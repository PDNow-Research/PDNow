{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_Exact_Replication_Experiment3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyubeU+Wz4R8+qcQ+qfln1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PDNow-Research/PDNow/blob/main/HandPD/SVM_Exact_Replication_Experiment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE4ruysJCQn7",
        "outputId": "8d1b703c-4e32-4f6f-ed3c-9ba8649d57e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Y4RF0dDEV2"
      },
      "source": [
        "# Data Science\n",
        "import re\n",
        "import csv\n",
        "import json\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# General\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "from datetime import date\n",
        "import warnings\n",
        "current_date = date.today()\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# SVM\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, average_precision_score, classification_report\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZTgvIpSDSKk"
      },
      "source": [
        "spiral_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewSpiral.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ka51zlVEk7r"
      },
      "source": [
        "meander_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewSpiral.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8GfG8Od97zF"
      },
      "source": [
        "spiral_df['ID_PATIENT'][spiral_df['_ID_EXAM'] == \"P26\"] = 32\n",
        "meander_df['ID_PATIENT'][meander_df['_ID_EXAM'] == \"P26\"] = 32"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRr7ykmLqIce",
        "outputId": "975ea1f4-b7d8-49b6-a504-9e8724cf8426"
      },
      "source": [
        "spiral_df.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['_ID_EXAM', 'IMAGE_NAME', 'ID_PATIENT', 'CLASS_TYPE', 'GENDER',\n",
              "       'RIGH/LEFT-HANDED', 'AGE', 'RMS', 'MAX_BETWEEN_ET_HT',\n",
              "       'MIN_BETWEEN_ET_HT', 'STD_DEVIATION_ET_HT', 'MRT', 'MAX_HT', 'MIN_HT',\n",
              "       'STD_HT', 'CHANGES_FROM_NEGATIVE_TO_POSITIVE_BETWEEN_ET_HT'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGBnOZkJkLHl"
      },
      "source": [
        "# extracting necessary columns from spiral df\n",
        "X_spiral = spiral_df[['RMS', 'MAX_BETWEEN_ET_HT', 'MIN_BETWEEN_ET_HT', 'STD_DEVIATION_ET_HT', 'MRT', 'MAX_HT', 'MIN_HT', 'STD_HT', 'CHANGES_FROM_NEGATIVE_TO_POSITIVE_BETWEEN_ET_HT']]\n",
        "y_spiral = spiral_df[['CLASS_TYPE']]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxINl8cckPmX"
      },
      "source": [
        "# extracting necessary columns from meander df\n",
        "X_meander = meander_df[['RMS', 'MAX_BETWEEN_ET_HT', 'MIN_BETWEEN_ET_HT', 'STD_DEVIATION_ET_HT', 'MRT', 'MAX_HT', 'MIN_HT', 'STD_HT', 'CHANGES_FROM_NEGATIVE_TO_POSITIVE_BETWEEN_ET_HT']]\n",
        "y_meander = meander_df[['CLASS_TYPE']]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYbNZkMjkfdw"
      },
      "source": [
        "##**Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcwtQpQfktl7"
      },
      "source": [
        "###**Normalization**\n",
        "\n",
        "fi' = (fi - avg)/std"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTfbmKgjjFEt"
      },
      "source": [
        "# normalization with the paper's method (formula above)\n",
        "def feature_normalization(df):\n",
        "  avg_dev = df.mad(axis = 0)\n",
        "  std_dev = df.std(axis = 0)\n",
        "\n",
        "  df = df.sub(avg_dev)\n",
        "  df = df.divide(std_dev)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4px6A393Q__"
      },
      "source": [
        "# normalizing X_spiral\n",
        "X_spiral = feature_normalization(X_spiral)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi7MJQt53h3-"
      },
      "source": [
        "# normalizing X_meander\n",
        "X_meander = feature_normalization(X_meander)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbeBsENVlQka"
      },
      "source": [
        "###Train-Test-Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5LoRggSlWmb"
      },
      "source": [
        "def data_split_experiment_3(X,y):# Train-Test Split, 80% train, 20% test, stratification across PD diagnosis (label)\n",
        "  y_label = y.to_numpy()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.25, stratify =y_label)\n",
        "\n",
        "  X_train = X_train.reset_index(drop = True)\n",
        "  X_test = X_test.reset_index(drop = True)  \n",
        "\n",
        "  y_train = y_train.reset_index(drop = True)\n",
        "  y_test = y_test.reset_index(drop = True)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdPiieKo1XbB"
      },
      "source": [
        "1. try without stratified label perhaps because we want to avoid shuffle for experiment 3? even if it shuffles, it should choose the right patient since it shuffles together. It then resets for easiness, but right patient should be preserved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-1hFnrflXcY"
      },
      "source": [
        "X_spiral_train, X_spiral_test, y_spiral_train, y_spiral_test = data_split_experiment_3(X_spiral,y_spiral)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQkGWuYAAGnn"
      },
      "source": [
        "##**SVM Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkfLD_4uq8lB",
        "outputId": "492eb477-1e35-4934-87cc-aeeafd6f69b0"
      },
      "source": [
        "score_arr = []\n",
        "\n",
        "for i in range(20):\n",
        "\n",
        "  X_spiral = feature_normalization(X_spiral)\n",
        "  X_meander = feature_normalization(X_meander)\n",
        "\n",
        "  X_meander_train, X_meander_test, y_meander_train, y_meander_test = data_split_experiment_3(X_meander,y_meander)\n",
        "  X_spiral_train, X_spiral_test, y_spiral_train, y_spiral_test = data_split_experiment_3(X_spiral,y_spiral)\n",
        "\n",
        "  clf = SVC(kernel = 'rbf', probability = True, class_weight = 'balanced')\n",
        "  clf.fit(X_meander_train, y_meander_train)\n",
        "\n",
        "  meander_score = clf.score(X_meander_test, y_meander_test)\n",
        "\n",
        "  y_pred = clf.predict(X_meander_test)\n",
        "  meander_recall = recall_score(y_meander_test, y_pred)\n",
        "  meander_precision = precision_score(y_meander_test, y_pred)\n",
        "\n",
        "\n",
        "  clf1 = SVC(kernel = 'rbf', probability = True, class_weight = 'balanced')\n",
        "  clf1.fit(X_spiral_train, y_spiral_train)\n",
        "\n",
        "  spiral_score = clf1.score(X_spiral_test, y_spiral_test)\n",
        "\n",
        "  y_pred = clf1.predict(X_spiral_test)\n",
        "  spiral_recall = recall_score(y_spiral_test, y_pred)\n",
        "  spiral_precision = precision_score(y_spiral_test, y_pred)\n",
        "\n",
        "\n",
        "  spiral_ov = (spiral_score + spiral_recall + spiral_precision)/3\n",
        "  meander_ov = (meander_score + meander_recall + meander_precision)/3\n",
        "\n",
        "\n",
        "  if (spiral_ov > meander_ov): # consider recall and such too? will there be one with highest recall, precision, and accuracy?\n",
        "    score = spiral_score\n",
        "    y_pred = clf.predict(X_spiral_test)\n",
        "    conf_mat = confusion_matrix(y_spiral_test, y_pred)\n",
        "  else:\n",
        "    score = meander_score\n",
        "    y_pred = clf.predict(X_meander_test)\n",
        "    conf_mat = confusion_matrix(y_meander_test, y_pred)\n",
        "\n",
        "  score_arr.append(score)\n",
        "  print(conf_mat)\n",
        "  print('')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n",
            "[[35  0]\n",
            " [31  0]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LFN0etH24-6",
        "outputId": "5dfcffd9-58d5-4c7d-ff23-8bf775a8350b"
      },
      "source": [
        "score_arr"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303,\n",
              " 0.5303030303030303]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au29-aTT6R8V",
        "outputId": "ba964a54-4655-4133-fc6f-7055f34e4d7e"
      },
      "source": [
        "np.mean(score_arr)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.531818181818182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7CxfB_A6abs",
        "outputId": "7da059a2-e7eb-469c-ea0b-33ce4311682d"
      },
      "source": [
        "np.std(score_arr)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.220446049250313e-16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GsYD5zqAKk9"
      },
      "source": [
        "The SVM approaches 53.03% always at some point. Perhaps there is a local minimum in the loss function it can't get out of?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q-82qHV56E3"
      },
      "source": [
        "Can we somehow get the weights for the model to learn which features are considered most useful?"
      ]
    }
  ]
}