{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Images.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLFqHb/R2j6e5B9MouUpEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PDNow-Research/PDNow/blob/main/HandPD/NeuralNets/NN_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGertFcjmEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d810774a-d425-4e24-e112-d5b2132ae2b8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9pOrBx_4cC"
      },
      "source": [
        "We are going to take text-based features and apply a simple, fully-connected neural network to them. Atually, let's use images - that's what the tutorial does. Let's only consider Meander for the time being."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eF1D-LjzNr"
      },
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Image Reading\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Other ML Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Torch General\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn # loss functions, neural network type (convolutional, linear, etc.)\n",
        "import torch.optim as optim # optimization functions (sgd)\n",
        "import torch.nn.functional as F # functions without parameters - activation functions (Relu, etc.) (also included in nn package, could use, but functional package is \"better\")\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets # torch has a LOT LOT LOT of standard datasets (ImageNet, MNIST, etc.)\n",
        "import torchvision.transforms as transforms # transformations for dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # PyTorch train test split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7oC7YSPkdtG"
      },
      "source": [
        "## Set Device + Init Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3nthTPetEQf"
      },
      "source": [
        "# Hyperparams\n",
        "input_size = 621432 \n",
        "# This 621432 comes from the size of each image (maxSize of an image). They have all been padded to be of this size. \n",
        "# We removed color channels to decrease size.\n",
        "num_classes = 2\n",
        "\n",
        "# tunables\n",
        "test_size = 0.1\n",
        "learning_rate = 0.1\n",
        "batch_size = 64\n",
        "num_epochs = 100\n",
        "seed = 0 # just random state to start at"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJcm8-PNalT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0d3fc4-50fa-4af2-b053-340c8df3e33d"
      },
      "source": [
        "# Device set \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # google colab provides cuda gpu\n",
        "print (device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FL-1eHknDM"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5gu2CV-kn8"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QSHyNkXuZAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3cadf688-d8df-4d07-ad3a-968dd37a70d4"
      },
      "source": [
        "# Load Data (possible to do it with Google Drive rather than uploading from computer?).\n",
        "# Uploaded can be nice tho... especially because it automatically goes to dictionary... that can be fed into NN, with file names as indexes - quite nice\n",
        "\n",
        "\"\"\" from google.colab import files\n",
        "uploaded = files.upload()\"\"\"\n",
        "\n",
        "# %cd \"/content/drive/\"My Drive\"/Data/Images/Meander/\"\n",
        "# X_train = np.load('HealthyMeander/HealthyMeander/')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' from google.colab import files\\nuploaded = files.upload()'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUoREyiB1uh8"
      },
      "source": [
        "# Healthy: Class 0 . PD: Class 1\n",
        "\n",
        "def extract_images(path, c): # path of data, class of data\n",
        "  filename_arr = []\n",
        "  X_arr = []\n",
        "\n",
        "  for file in glob.glob(path):\n",
        "    filename_arr.append(file) # filenames, not going to use them for now. Might need them later.\n",
        "    x = cv2.imread(file)\n",
        "    x = x[:,:,0] # removing all color channels to make data smaller and possible to use\n",
        "    X_arr.append(x)\n",
        "\n",
        "  y_arr = [c] * len(X_arr)\n",
        "\n",
        "  return X_arr, y_arr\n",
        "\n",
        "# X_arr is a list of 3D arrays representing images"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocDBvBlTGSuf"
      },
      "source": [
        "# possibly try different pad modes for better NN results? (instead of 'constant')\n",
        "def pad_images(arr):\n",
        "  arr = np.copy(arr)\n",
        "  largestX = 0\n",
        "  largestY = 0\n",
        "\n",
        "  def pad_condition(pad, largest, index):\n",
        "    if (2 * pad != (largest - arr[i].shape[index])):\n",
        "      pad1 = pad + 1\n",
        "      pad2 = pad\n",
        "    else:\n",
        "      pad1, pad2 = pad, pad\n",
        "    return pad1, pad2\n",
        "\n",
        "  for i in arr:\n",
        "    X = i.shape[0]\n",
        "    Y = i.shape[1]\n",
        "    if (X > largestX):\n",
        "      largestX = X\n",
        "    if (Y > largestY):\n",
        "      largestY = Y\n",
        "\n",
        "  for i in range(len(arr)):\n",
        "    X_pad = int((largestX - arr[i].shape[0]) /2) # pad equally in both directions, must be int\n",
        "    Y_pad = int((largestY - arr[i].shape[1]) /2)\n",
        "    \n",
        "    # but int floors, so we might get something of a slightly wrong shape (by 1), so...\n",
        "    X_pad1, X_pad2 = pad_condition(X_pad, largestX, 0)\n",
        "    Y_pad1, Y_pad2 = pad_condition(Y_pad, largestY, 1)\n",
        "\n",
        "    arr[i] = np.pad(arr[i], ((X_pad1, X_pad2), (Y_pad1, Y_pad2)), 'constant', constant_values=(0)) # each image in arr in 2D\n",
        "\n",
        "  maxSize = largestX * largestY\n",
        "  \n",
        "  return arr, maxSize"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgoIIjwgRJWk"
      },
      "source": [
        "def normalize_images(arr, num):\n",
        "  arr = arr/num\n",
        "  return arr"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "VaW62V2UM-en",
        "outputId": "8b153fc3-d382-44f2-fc2a-539fafad99b6"
      },
      "source": [
        "\"\"\" X_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\n",
        "X_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\n",
        "\n",
        "X_all = X_meah + X_meap\n",
        "X_all, maxSize = pad_images(X_all)\n",
        "\n",
        "X_all = normalize_images(X_all, 255)\n",
        "\n",
        "y_all = np.array(y_meah + y_meap)\n",
        "\n",
        "# Why the warning particularly? \"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' X_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\\nX_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\\n\\nX_all = X_meah + X_meap\\nX_all, maxSize = pad_images(X_all)\\n\\nX_all = normalize_images(X_all, 255)\\n\\ny_all = np.array(y_meah + y_meap)\\n\\n# Why the warning particularly? '"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTuX0ihosiD"
      },
      "source": [
        "class MeanderDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # data loading\n",
        "    X_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\n",
        "    X_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\n",
        "\n",
        "    X_spih, y_spih = extract_images(\"/content/drive/MyDrive/Data/Images/Spiral/HealthySpiral/HealthySpiral/*.*\",0)\n",
        "    X_spip, y_spip = extract_images(\"/content/drive/MyDrive/Data/Images/Spiral/PatientSpiral/PatientSpiral/*.*\",1)\n",
        "\n",
        "\n",
        "    y_all = np.array(y_meah + y_meap + y_spih + y_spip)\n",
        "\n",
        "    X_all = X_meah + X_meap + X_spih + X_spip\n",
        "    X_all, maxSize = pad_images(X_all) # just padding all of the array's images to be the same size\n",
        "    X_all = normalize_images(X_all, 255) # normalizing from 0 to 255 - 0 to 1\n",
        "\n",
        "    X_all = np.stack(X_all, axis=0) # stacking into 4D tensor\n",
        "\n",
        "    self.n_samples = X_all.shape[0]\n",
        "\n",
        "    self.x = torch.from_numpy(X_all).float() # creates tensor from numpy array, making it float as expected by model\n",
        "    self.y = torch.from_numpy(y_all).long() # y_all is numpy array too, making it a long as expected by model\n",
        "    self.inputSize = maxSize\n",
        "  \n",
        "  # support indexing such that dataset[i] can be used to get i-th sample\n",
        "  def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "  # to return size\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5rlj-zaatPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a1612e-e32e-4a28-9908-f16b68744bc2"
      },
      "source": [
        "dataset = MeanderDataset() # Meander Dataset object\n",
        "\n",
        "# Why the warning?"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:792: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, order=order, subok=subok, copy=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqUTkoL3gaM7",
        "outputId": "02e41741-8da7-46e7-d64c-02f0afb31f2e"
      },
      "source": [
        "dataset.inputSize"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "621432"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOCtKHuXv33-"
      },
      "source": [
        "first_row = dataset[0]\n",
        "feature0, label0 = first_row\n",
        "print(feature0, label0)\n",
        "\n",
        "# feature0 shape is 744, 822, 3\n",
        "# label0 is just 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4NmhAIIwV-",
        "outputId": "6a4541db-d7d0-4eaf-9510-f9cd1b09c0bf"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "528"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzYiS7yNNxBQ"
      },
      "source": [
        "### DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYxhzwoMiga"
      },
      "source": [
        "# Dataloader to load whole dataset\n",
        "# Shuffle: shuffle data, good for training\n",
        "# num_workers: faster loading with multiple subprocesses simultaneously, set to 0 if error occurs when loading"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vfo8yMzBh_b"
      },
      "source": [
        "# To perform train test split, we'll use sklearn... https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
        "\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, test_indices, _ , _ = train_test_split(\n",
        "    range(len(dataset)),\n",
        "    dataset.y,\n",
        "    stratify=dataset.y,\n",
        "    test_size=test_size,\n",
        "    random_state=seed\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk9e_kh9JPcR"
      },
      "source": [
        "# train_indices is indices of the training values while test_indices is indicies of the testing values. Let's split our data like such.\n",
        "\n",
        "# generate subset based on indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "test_dataset = Subset(dataset, test_indices)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NNckzyJgiR",
        "outputId": "effb24c3-b1ce-4c2f-ee9e-c1d16629aa12"
      },
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(475, 53)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy29psB1Z8L"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers =2)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True, num_workers =2)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMbr3JjulNJI"
      },
      "source": [
        "## Defining the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGjWjPnA2w3"
      },
      "source": [
        "Now to create the fully connected network.\n",
        "\n",
        "Unfortunately, there is a limit to the model's performance. More nodes would have been helpful, but we don't have those resources. We need to cut down on the model images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_16mfP3JkKp9"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, output_size): # input-size = 611568 (size of our images, pixel number), num_classes = 2 (PD/no PD)\n",
        "    super(NN, self).__init__() # initializes the NN class that we're defining\n",
        "    self.fc1 = nn.Linear(input_size, 200)\n",
        "    self.dt1 = nn.Dropout(0.1, inplace=False)\n",
        "    self.fc2 = nn.Linear(200, 50) # 2 million to 500 thousand\n",
        "    self.fc3 = nn.Linear(50, 5) \n",
        "    self.fc4 = nn.Linear(5, output_size)\n",
        "\n",
        "  def forward(self, x): # run on some input x, which is the images which we run through fc1 and fc2 layers created above (and add the reLU activation function it between)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dt1(x)\n",
        "    x = torch.sigmoid(self.fc2(x)) # functional library.sigmoid is deprecated\n",
        "    x = torch.sigmoid(self.fc3(x))\n",
        "    x = F.softmax(self.fc4(x))\n",
        "    return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJ98iivMqS6"
      },
      "source": [
        "### Quick Test\n",
        "\n",
        "What the model should output it something of shape [264 (140 + 124), 2]. For each image, it should predict the probability of it being in class 1 or 2 and return both of those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JHWnwgXgg9NY",
        "outputId": "f1df194c-9039-4f59-c5e2-48b5f18e2374"
      },
      "source": [
        "\"\"\" model = NN(621432, 2) \n",
        "\n",
        "# 124 patient images\n",
        "# 140 control images \n",
        "x = torch.randn(64, 621432) # 64 batch size\n",
        "\n",
        "print (model(x).shape)\"\"\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' model = NN(621432, 2) \\n\\n# 124 patient images\\n# 140 control images \\nx = torch.randn(64, 621432) # 64 batch size\\n\\nprint (model(x).shape)'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTx3jhOBK8Ns"
      },
      "source": [
        "## Initialize Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-SEtZyLAUE"
      },
      "source": [
        "model = NN(input_size = input_size, output_size = num_classes).to(device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUS61pUBLFvk"
      },
      "source": [
        "# Loss + Optimizer\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate) # optimizer function"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO7z25t4KIWY"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "CCNdQnCYKKxk",
        "outputId": "9de21a5b-73ca-43be-df5a-06aa9d486f50"
      },
      "source": [
        "# epochs: number of times network sees images. 1 epoch - seen all images once\n",
        "\n",
        "loss_values = [] * 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader): # parts of the train_loader, (data,targets) in tuple together, batch_idx there before\n",
        "        \n",
        "        # Get data to cuda (that's our device, if it's possible)\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # Get to correct shape, which is one long, unrolled, vector of size 744 * 822 * 3 = 1834704\n",
        "        data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "        # by looking at this, we see we have 4 batches: 3 of size 64, 1 of size 19. Also, our shape is right now.\n",
        "        # print (data.shape)\n",
        "\n",
        "        # forward (why called forward??) - forward propagation\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # backward (why called backward??) - backward propagation\n",
        "        optimizer.zero_grad() # set all gradients to 0 for each batch so it doesnt store calculation from previous batch\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_values.append(loss)\n",
        "\n",
        "plt.plot(np.array(loss_values), 'r')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f670470a3d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBJOAYXNn38"
      },
      "source": [
        "## Check Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgWgMQdNpMe"
      },
      "source": [
        "def check_accuracy(loader, model):\n",
        "  \"\"\" if loader.dataset.train: # if this is true, then it is loading and checking training data\n",
        "    print ('Checking accuracy on training data')\n",
        "  else: \n",
        "    print ('Checking accuracy on testing data')\n",
        "\n",
        "  Appears to be error with this code  \n",
        "  \"\"\"\n",
        "\n",
        "  # initializing\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "\n",
        "  model.eval() # why this specifically?\n",
        "\n",
        "  with torch.no_grad(): # so we don't have to compute gradients for accuracy\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device)\n",
        "      y = y.to(device=device)\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "      scores = model(x)\n",
        "\n",
        "      # scores is size 264 * 2\n",
        "      # _, is don't store this part in anything\n",
        "      _, predictions = scores.max(1) # gives us index of maximum score value (max along second dimension, reason for the 1) in predictions variable each time\n",
        "      num_correct += (predictions == y).sum()\n",
        "      num_samples += predictions.size(0)\n",
        "\n",
        "  model.train()\n",
        "  acc = num_correct/num_samples\n",
        "  return acc"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzthtBRLOh4G",
        "outputId": "645ed25d-6eab-46ee-e0b9-e1efcd2f719e"
      },
      "source": [
        "# running check_accuracy on training and test set\n",
        "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
        "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 46.95\n",
            "Accuracy on test set: 47.17\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}