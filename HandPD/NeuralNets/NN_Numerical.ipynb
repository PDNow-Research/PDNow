{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Numerical.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPeuzSi8tL78b34Q73hytaD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PDNow-Research/PDNow/blob/main/HandPD/NeuralNets/NN_Numerical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGertFcjmEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e803b9-1c8f-4744-e720-da99f1da8789"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9pOrBx_4cC"
      },
      "source": [
        "We are going to take text-based features and apply a simple, fully-connected neural network to them. Atually, let's use images - that's what the tutorial does. Let's only consider Meander for the time being."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eF1D-LjzNr"
      },
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Image Reading\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Other ML Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Torch General\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn # loss functions, neural network type (convolutional, linear, etc.)\n",
        "import torch.optim as optim # optimization functions (sgd)\n",
        "import torch.nn.functional as F # functions without parameters - activation functions (Relu, etc.) (also included in nn package, could use, but functional package is \"better\")\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets # torch has a LOT LOT LOT of standard datasets (ImageNet, MNIST, etc.)\n",
        "import torchvision.transforms as transforms # transformations for dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # PyTorch train test split"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvwBQmamlFeR"
      },
      "source": [
        "First to load the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7oC7YSPkdtG"
      },
      "source": [
        "## Set Device + Init Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJcm8-PNalT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbe1a1d-8b69-48ae-96d1-e6a1908f0fc2"
      },
      "source": [
        "# Device set \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # google colab provides cuda gpu\n",
        "print (device)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3nthTPetEQf"
      },
      "source": [
        "# Hyperparams\n",
        "input_size = 9 # size of 1 row of data\n",
        "num_classes = 2 # which is output_size\n",
        "\n",
        "# tunables\n",
        "test_size = 0.2\n",
        "learning_rate = 0.01\n",
        "batch_size = 256\n",
        "num_epochs = 150\n",
        "seed = 0 # just random state to start at"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FL-1eHknDM"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5gu2CV-kn8"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QSHyNkXuZAX"
      },
      "source": [
        "# Fix Duplicates\n",
        "# Our duplicates are 5, 23, 31 patient_ids\n",
        "def fix_duplicate_ids(df, patient_ids, exam_ids, new_ids):\n",
        "\n",
        "  df = df.copy()\n",
        "  \n",
        "  for i in range(len(patient_ids)): # don't need the actually patient_id numbers, but important that user knows what they are\n",
        "    df[\"ID_PATIENT\"][df[\"_ID_EXAM\"] == exam_ids[i]] = new_ids[i]\n",
        "\n",
        "  return df"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6s3QrYpvRN"
      },
      "source": [
        "def feature_normalization(df):\n",
        "\n",
        "  avg_dev = df.mad(axis = 0)\n",
        "  std_dev = df.std(axis = 0)\n",
        "\n",
        "  df = df.sub(avg_dev)\n",
        "  df = df.divide(std_dev)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTuX0ihosiD"
      },
      "source": [
        "class PDDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # Data loading\n",
        "    spiral_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewSpiral.csv')\n",
        "    meander_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewMeander.csv')\n",
        "\n",
        "    data_all = pd.concat((spiral_df, meander_df))\n",
        "    data_all = fix_duplicate_ids(data_all, [5, 23, 31], ['P25', 'P3', 'P26'], [500, 501, 502])\n",
        "\n",
        "    # Normalization\n",
        "    X = data_all[['RMS', 'MAX_BETWEEN_ET_HT', 'MIN_BETWEEN_ET_HT', 'STD_DEVIATION_ET_HT', 'MRT', 'MAX_HT', 'MIN_HT','STD_HT', 'CHANGES_FROM_NEGATIVE_TO_POSITIVE_BETWEEN_ET_HT']]\n",
        "    X = feature_normalization(X)\n",
        "    \n",
        "    # We must avoid shuffling the data now. It should stay in order all throughout the process\n",
        "    X = X.to_numpy(dtype=float)\n",
        "    y = data_all['CLASS_TYPE'].to_numpy()\n",
        "    \n",
        "    y = y - 1 # so we have labels 0 and 1, not 1 and 2\n",
        "\n",
        "    self.n_samples = data_all.shape[0]\n",
        "\n",
        "    self.x = torch.from_numpy(X).float() # creates tensor from numpy array, making it float as expected by model\n",
        "    self.y = torch.from_numpy(y).long() # y_all is numpy array too, making it a long as expected by model\n",
        "  \n",
        "  # support indexing such that dataset[i] can be used to get i-th sample\n",
        "  def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "  # to return size\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5rlj-zaatPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ed46bc-26ad-4290-b344-8cdc87e67efd"
      },
      "source": [
        "dataset = PDDataset() # Meander Dataset object\n",
        "\n",
        "# Why the warning?"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOCtKHuXv33-",
        "outputId": "7836fb69-d6b4-4794-dcc6-34d2e2c82811"
      },
      "source": [
        "first_row = dataset[0]\n",
        "feature0, label0 = first_row\n",
        "print(feature0, label0)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 7.1436,  7.8385,  3.2998, -0.1434,  4.7975,  8.7665, -0.2707,  4.8289,\n",
            "         0.8604]) tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4NmhAIIwV-",
        "outputId": "22d8dfa9-6713-47e3-f4fa-588266693d73"
      },
      "source": [
        "len(dataset) # make sense, 264 * 2"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "528"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzYiS7yNNxBQ"
      },
      "source": [
        "### DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYxhzwoMiga"
      },
      "source": [
        "# Dataloader to load whole dataset\n",
        "# Shuffle: no shuffle should happen! We don't want to mix up the data, since patient info must correspond with the proper labels for diagnosis\n",
        "# num_workers: faster loading with multiple subprocesses simultaneously, set to 0 if error occurs when loading"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vfo8yMzBh_b"
      },
      "source": [
        "# To perform train test split, we'll use sklearn... https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, test_indices, _ , _ = train_test_split(\n",
        "    range(len(dataset)),\n",
        "    dataset.y,\n",
        "    stratify=dataset.y,\n",
        "    test_size=test_size,\n",
        "    random_state=seed\n",
        ")"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk9e_kh9JPcR"
      },
      "source": [
        "# train_indices is indices of the training values while test_indices is indicies of the testing values. Let's split our data like such.\n",
        "\n",
        "# can I concatenate to a dataset object??? we wont worry about it right now. This is for patient level diagnosis...\n",
        "\n",
        "# generate subset based on indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "test_dataset = Subset(dataset, test_indices)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j3h00VAeRqe",
        "outputId": "ea84d060-8a7b-489c-accf-547604105281"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.Subset at 0x7f009ac10d10>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NNckzyJgiR",
        "outputId": "04125cc7-d783-4fcc-d6d2-5423243ef81d"
      },
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(422, 106)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy29psB1Z8L"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers =2)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True, num_workers =2)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G2v9AbplQ3_"
      },
      "source": [
        "## Defining the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUNYEAhmT3Zd"
      },
      "source": [
        "ACTIVATION FUNCTION DECIDES WHAT IS SENT TO THE NEXT LAYER - IT IS between LAYERS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGjWjPnA2w3"
      },
      "source": [
        "Now to create the fully connected network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_16mfP3JkKp9"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, output_size): # input-size = 9, num_classes = 2 (PD/no PD), which is the output size for each row\n",
        "\n",
        "    super(NN, self).__init__() # initializes the NN class that we're defining\n",
        "    self.fc1 = nn.Linear(input_size, 64) # 5000 nodes - WAYY too much\n",
        "    self.dt1 = nn.Dropout(0.1, inplace=False)\n",
        "    self.fc2 = nn.Linear(64, 16)\n",
        "    self.fc3 = nn.Linear(16, output_size)\n",
        "    #self.hd1 = nn.Linear(32, hidden_size1)\n",
        "    \n",
        "    #self.hd2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "    \n",
        "\n",
        "  def forward(self, x): # run on some input x, which is the images which we run through fc1 and fc2 layers created above (and add the reLU activation function it between)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # x = F.relu(self.hd1(x))\n",
        "    x = self.dt1(x)\n",
        "    x = torch.sigmoid(self.fc2(x)) # functional library.sigmoid is deprecated\n",
        "    # x = F.relu(self.hd2(x))\n",
        "    x = F.softmax(self.fc3(x))\n",
        "    return x"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJ98iivMqS6"
      },
      "source": [
        "### Quick Test\n",
        "\n",
        "What the model should output it something of shape [264 (140 + 124), 2]. For each image, it should predict the probability of it being in class 1 or 2 and return both of those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHUZ9XHGEaVa",
        "outputId": "d32db5f6-c679-4efa-f656-2be4b3e56bdc"
      },
      "source": [
        "# input-size really refers to the size of 1 row of data.\n",
        "# batch-size is the number of rows being fed to the model at one time\n",
        "\n",
        "model = NN(9, 2) \n",
        "print (model)\n",
        "\n",
        "# 264 spiral, 264 meander images\n",
        "# 35 non PD patients, 31 PD patients, each who drew 4 spirals and 4 meanders\n",
        "x = torch.randn(64, 9) # 64 batch size, 9 x 1 is the size of 1 row of data. This is the shape of what will be fed to the model at one time. (2D array of 64 x 9)\n",
        "print (model(x).shape)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (fc1): Linear(in_features=9, out_features=64, bias=True)\n",
            "  (dt1): Dropout(p=0.1, inplace=False)\n",
            "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
            "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
            ")\n",
            "torch.Size([64, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiZh08qdBNUu",
        "outputId": "6c69849a-646b-4b1c-bd01-ef0c35fb09f8"
      },
      "source": [
        "print (model(x)[0:10])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3639, 0.6361],\n",
            "        [0.3331, 0.6669],\n",
            "        [0.3283, 0.6717],\n",
            "        [0.3211, 0.6789],\n",
            "        [0.3233, 0.6767],\n",
            "        [0.3143, 0.6857],\n",
            "        [0.3391, 0.6609],\n",
            "        [0.3364, 0.6636],\n",
            "        [0.3362, 0.6638],\n",
            "        [0.3413, 0.6587]], grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTx3jhOBK8Ns"
      },
      "source": [
        "## Initialize Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-SEtZyLAUE"
      },
      "source": [
        "model = NN(input_size = input_size, output_size = num_classes).to(device) # input-size??"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUS61pUBLFvk"
      },
      "source": [
        "# Loss + Optimizer\n",
        "criterion = nn.BCELoss() # loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate) # optimizer function"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO7z25t4KIWY"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CCNdQnCYKKxk",
        "outputId": "670bf876-1adb-4f61-d7e4-3ca9f6e36260"
      },
      "source": [
        "# epochs: number of times network sees images. 1 epoch - seen all images once\n",
        "loss_values = [] * 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader): # parts of the train_loader, (data,targets) in tuple together, batch_idx there before\n",
        "        \n",
        "        # Get data to cuda (that's our device, if it's possible)\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # forward propagation\n",
        "        scores = model(data)\n",
        "        scores = scores.to(device=torch.device('cpu')).detach().numpy()\n",
        "\n",
        "        print (type(scores))\n",
        "\n",
        "        print (scores.shape)\n",
        "        print(scores)\n",
        "\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # backward propagation\n",
        "        optimizer.zero_grad() # set all gradients to 0 for each batch so it doesnt store calculation from previous batch\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_values.append(loss) # loss after each epoch\n",
        "\n",
        "plt.plot(np.array(loss_values), 'r')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(256, 2)\n",
            "[[0.505924   0.49407598]\n",
            " [0.503914   0.49608597]\n",
            " [0.48056403 0.51943594]\n",
            " [0.47380224 0.5261978 ]\n",
            " [0.44168296 0.558317  ]\n",
            " [0.4766823  0.5233177 ]\n",
            " [0.46155965 0.53844035]\n",
            " [0.43219367 0.56780636]\n",
            " [0.45969793 0.5403021 ]\n",
            " [0.4673095  0.5326905 ]\n",
            " [0.457274   0.54272604]\n",
            " [0.48591265 0.5140874 ]\n",
            " [0.46092278 0.5390772 ]\n",
            " [0.46526715 0.5347329 ]\n",
            " [0.42525315 0.57474685]\n",
            " [0.46399477 0.53600526]\n",
            " [0.47157875 0.5284212 ]\n",
            " [0.47022676 0.5297733 ]\n",
            " [0.46815795 0.5318421 ]\n",
            " [0.4810006  0.5189994 ]\n",
            " [0.45401448 0.5459855 ]\n",
            " [0.4817831  0.5182169 ]\n",
            " [0.4830567  0.51694334]\n",
            " [0.45645928 0.5435407 ]\n",
            " [0.47358778 0.5264122 ]\n",
            " [0.45668787 0.54331213]\n",
            " [0.45663735 0.5433626 ]\n",
            " [0.49122015 0.5087799 ]\n",
            " [0.5040576  0.49594238]\n",
            " [0.45797226 0.5420278 ]\n",
            " [0.46833315 0.5316668 ]\n",
            " [0.4861105  0.5138895 ]\n",
            " [0.49619097 0.50380903]\n",
            " [0.46767828 0.53232175]\n",
            " [0.46262652 0.5373734 ]\n",
            " [0.47819895 0.52180105]\n",
            " [0.46437126 0.53562874]\n",
            " [0.4843688  0.5156312 ]\n",
            " [0.48983517 0.5101648 ]\n",
            " [0.466498   0.533502  ]\n",
            " [0.4740233  0.52597666]\n",
            " [0.46652934 0.5334707 ]\n",
            " [0.46348703 0.536513  ]\n",
            " [0.48291248 0.5170876 ]\n",
            " [0.47177747 0.52822256]\n",
            " [0.4659152  0.5340848 ]\n",
            " [0.4583683  0.54163164]\n",
            " [0.4602473  0.53975266]\n",
            " [0.46839437 0.5316056 ]\n",
            " [0.47234458 0.5276554 ]\n",
            " [0.4541747  0.5458253 ]\n",
            " [0.47472662 0.5252734 ]\n",
            " [0.4877865  0.51221347]\n",
            " [0.46967682 0.53032315]\n",
            " [0.45706394 0.542936  ]\n",
            " [0.47909114 0.5209089 ]\n",
            " [0.4371548  0.56284523]\n",
            " [0.49054885 0.5094512 ]\n",
            " [0.45784128 0.5421587 ]\n",
            " [0.45403242 0.54596764]\n",
            " [0.47713658 0.52286345]\n",
            " [0.49869072 0.5013093 ]\n",
            " [0.46327138 0.5367286 ]\n",
            " [0.52239937 0.47760063]\n",
            " [0.4813269  0.5186731 ]\n",
            " [0.43960783 0.5603922 ]\n",
            " [0.47807783 0.5219222 ]\n",
            " [0.48258376 0.51741624]\n",
            " [0.46628287 0.5337171 ]\n",
            " [0.48456752 0.5154325 ]\n",
            " [0.46833068 0.5316693 ]\n",
            " [0.46925932 0.5307407 ]\n",
            " [0.4609812  0.5390188 ]\n",
            " [0.49353486 0.5064652 ]\n",
            " [0.45743126 0.54256874]\n",
            " [0.4641257  0.5358743 ]\n",
            " [0.43668947 0.56331056]\n",
            " [0.49584797 0.50415206]\n",
            " [0.4531611  0.54683894]\n",
            " [0.49786606 0.50213397]\n",
            " [0.4706158  0.5293842 ]\n",
            " [0.4554457  0.54455435]\n",
            " [0.45944777 0.54055226]\n",
            " [0.4977894  0.50221056]\n",
            " [0.46706218 0.5329378 ]\n",
            " [0.4766824  0.5233176 ]\n",
            " [0.47606248 0.5239375 ]\n",
            " [0.4690345  0.5309655 ]\n",
            " [0.46042374 0.53957623]\n",
            " [0.47599304 0.52400696]\n",
            " [0.4603377  0.5396623 ]\n",
            " [0.4801771  0.51982284]\n",
            " [0.46026933 0.53973067]\n",
            " [0.46493673 0.5350633 ]\n",
            " [0.49181387 0.5081861 ]\n",
            " [0.48513958 0.5148604 ]\n",
            " [0.46276075 0.53723925]\n",
            " [0.47827357 0.52172637]\n",
            " [0.45701602 0.542984  ]\n",
            " [0.48308122 0.5169188 ]\n",
            " [0.47796097 0.52203906]\n",
            " [0.45206013 0.5479399 ]\n",
            " [0.47750887 0.52249116]\n",
            " [0.45024183 0.54975814]\n",
            " [0.4695605  0.5304395 ]\n",
            " [0.46717352 0.5328265 ]\n",
            " [0.48433045 0.5156695 ]\n",
            " [0.48916495 0.51083505]\n",
            " [0.45112202 0.54887795]\n",
            " [0.4643907  0.5356093 ]\n",
            " [0.43120465 0.5687953 ]\n",
            " [0.45974198 0.54025805]\n",
            " [0.4749947  0.52500534]\n",
            " [0.4581293  0.5418707 ]\n",
            " [0.48888904 0.5111109 ]\n",
            " [0.45329928 0.54670066]\n",
            " [0.48883188 0.5111681 ]\n",
            " [0.4774367  0.5225633 ]\n",
            " [0.4534654  0.5465346 ]\n",
            " [0.47424293 0.5257571 ]\n",
            " [0.4623802  0.53761977]\n",
            " [0.4792978  0.52070224]\n",
            " [0.46368626 0.5363137 ]\n",
            " [0.50519305 0.49480695]\n",
            " [0.479168   0.520832  ]\n",
            " [0.46939364 0.5306064 ]\n",
            " [0.46932873 0.53067124]\n",
            " [0.44411084 0.5558891 ]\n",
            " [0.4668557  0.5331443 ]\n",
            " [0.47360468 0.5263953 ]\n",
            " [0.46669054 0.53330946]\n",
            " [0.41170594 0.5882941 ]\n",
            " [0.47621083 0.52378917]\n",
            " [0.46215945 0.53784055]\n",
            " [0.44599983 0.55400014]\n",
            " [0.4776849  0.5223151 ]\n",
            " [0.43376774 0.56623226]\n",
            " [0.4659059  0.5340941 ]\n",
            " [0.45400363 0.54599637]\n",
            " [0.45819545 0.54180455]\n",
            " [0.5209387  0.47906128]\n",
            " [0.46015263 0.5398474 ]\n",
            " [0.50068575 0.49931422]\n",
            " [0.45611647 0.5438835 ]\n",
            " [0.48918796 0.51081204]\n",
            " [0.47867706 0.52132297]\n",
            " [0.4747038  0.5252962 ]\n",
            " [0.46975434 0.5302457 ]\n",
            " [0.47990662 0.5200934 ]\n",
            " [0.46285743 0.5371426 ]\n",
            " [0.45894593 0.54105407]\n",
            " [0.47889864 0.52110136]\n",
            " [0.43357313 0.5664268 ]\n",
            " [0.47672594 0.52327406]\n",
            " [0.4593514  0.54064864]\n",
            " [0.50280327 0.49719676]\n",
            " [0.4654     0.5346    ]\n",
            " [0.4658372  0.5341628 ]\n",
            " [0.527182   0.47281802]\n",
            " [0.45497465 0.54502535]\n",
            " [0.4728291  0.5271709 ]\n",
            " [0.48707086 0.5129292 ]\n",
            " [0.45094815 0.5490519 ]\n",
            " [0.4757475  0.52425253]\n",
            " [0.5097422  0.49025783]\n",
            " [0.45830292 0.5416971 ]\n",
            " [0.43136597 0.5686341 ]\n",
            " [0.5002214  0.4997787 ]\n",
            " [0.4827287  0.51727134]\n",
            " [0.48259827 0.51740175]\n",
            " [0.51435983 0.48564014]\n",
            " [0.4545766  0.54542345]\n",
            " [0.4774898  0.5225102 ]\n",
            " [0.47051334 0.52948666]\n",
            " [0.4503707  0.54962933]\n",
            " [0.480778   0.519222  ]\n",
            " [0.45871186 0.54128814]\n",
            " [0.47717687 0.5228231 ]\n",
            " [0.4583655  0.5416345 ]\n",
            " [0.45704898 0.542951  ]\n",
            " [0.5029145  0.4970855 ]\n",
            " [0.43451986 0.5654802 ]\n",
            " [0.5011059  0.49889407]\n",
            " [0.4625943  0.53740567]\n",
            " [0.43494582 0.5650542 ]\n",
            " [0.4650825  0.5349175 ]\n",
            " [0.4662256  0.5337744 ]\n",
            " [0.46485552 0.53514445]\n",
            " [0.47032416 0.5296758 ]\n",
            " [0.46015757 0.5398424 ]\n",
            " [0.47383437 0.5261656 ]\n",
            " [0.46769258 0.5323074 ]\n",
            " [0.4807231  0.51927686]\n",
            " [0.46804005 0.53196   ]\n",
            " [0.46931052 0.5306895 ]\n",
            " [0.42548993 0.57451004]\n",
            " [0.44965288 0.5503471 ]\n",
            " [0.47629723 0.52370274]\n",
            " [0.4432818  0.5567182 ]\n",
            " [0.47449452 0.5255055 ]\n",
            " [0.4694726  0.5305274 ]\n",
            " [0.466641   0.533359  ]\n",
            " [0.479969   0.520031  ]\n",
            " [0.50127983 0.4987202 ]\n",
            " [0.46472955 0.53527045]\n",
            " [0.45500094 0.54499906]\n",
            " [0.46489325 0.5351067 ]\n",
            " [0.46128428 0.5387158 ]\n",
            " [0.45805484 0.5419451 ]\n",
            " [0.5111132  0.48888674]\n",
            " [0.45724514 0.5427548 ]\n",
            " [0.46418554 0.53581446]\n",
            " [0.45471948 0.5452805 ]\n",
            " [0.47328874 0.5267113 ]\n",
            " [0.45458075 0.5454193 ]\n",
            " [0.44766465 0.5523353 ]\n",
            " [0.45860818 0.54139185]\n",
            " [0.45594624 0.54405373]\n",
            " [0.47517568 0.5248243 ]\n",
            " [0.46558127 0.53441876]\n",
            " [0.472735   0.527265  ]\n",
            " [0.4650307  0.5349693 ]\n",
            " [0.46462065 0.5353794 ]\n",
            " [0.46376705 0.53623295]\n",
            " [0.46318305 0.53681695]\n",
            " [0.45733407 0.5426659 ]\n",
            " [0.49879706 0.50120294]\n",
            " [0.45763782 0.5423622 ]\n",
            " [0.4785471  0.5214529 ]\n",
            " [0.45596105 0.544039  ]\n",
            " [0.47246116 0.52753884]\n",
            " [0.46622488 0.5337751 ]\n",
            " [0.47833613 0.52166384]\n",
            " [0.511741   0.488259  ]\n",
            " [0.45960128 0.5403987 ]\n",
            " [0.4984308  0.5015692 ]\n",
            " [0.4440014  0.5559986 ]\n",
            " [0.4635958  0.53640425]\n",
            " [0.47231477 0.5276852 ]\n",
            " [0.48074046 0.5192596 ]\n",
            " [0.4438258  0.5561742 ]\n",
            " [0.47697976 0.52302027]\n",
            " [0.47983646 0.52016354]\n",
            " [0.479686   0.52031404]\n",
            " [0.48132807 0.51867193]\n",
            " [0.47655457 0.52344537]\n",
            " [0.4561774  0.5438226 ]\n",
            " [0.47659966 0.5234003 ]\n",
            " [0.44118348 0.5588165 ]\n",
            " [0.4682075  0.5317925 ]\n",
            " [0.47573203 0.52426803]\n",
            " [0.4188099  0.5811901 ]\n",
            " [0.48429888 0.5157011 ]\n",
            " [0.46869227 0.5313077 ]\n",
            " [0.4642514  0.5357486 ]\n",
            " [0.44986108 0.55013895]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-eadfec1bf29f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# backward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2881\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2882\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2883\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2884\u001b[0m         raise ValueError(\n\u001b[1;32m   2885\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBJOAYXNn38"
      },
      "source": [
        "## Check Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgWgMQdNpMe"
      },
      "source": [
        "def check_accuracy(loader, model):\n",
        "  \"\"\" if loader.dataset.train: # if this is true, then it is loading and checking training data\n",
        "    print ('Checking accuracy on training data')\n",
        "  else: \n",
        "    print ('Checking accuracy on testing data')\n",
        "\n",
        "  Appears to be error with this code  \n",
        "  \"\"\"\n",
        "\n",
        "  # initializing\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  y_pred = [] * 1\n",
        "  y_true = [] * 1\n",
        "\n",
        "  model.eval() # why this specifically?\n",
        "\n",
        "  with torch.no_grad(): # so we don't have to compute gradients for accuracy\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device)\n",
        "      y = y.to(device=device)\n",
        "\n",
        "      y_true.append(y)\n",
        "      \n",
        "      # reshape useless here\n",
        "      # x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "      scores = model(x)\n",
        "\n",
        "      # print (scores) # this returns 6 arrays of 64 x 2 and 1 of 38 x 2\n",
        "\n",
        "      # _, is don't store this part in anything\n",
        "      _, prediction = scores.max(1) # gives us index of maximum score value (max along second dimension, reason for the 1) in predictions variable each time\n",
        "      \n",
        "      y_pred.append(prediction)\n",
        "      \n",
        "      num_correct += (prediction == y).sum()\n",
        "      num_samples += prediction.size(0)\n",
        "\n",
        "  model.train()\n",
        "  acc = num_correct/num_samples\n",
        "  return acc, y_true, y_pred"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va66YK0T5Kin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7935c83f-35ac-4387-d05d-3b39d9545d9a"
      },
      "source": [
        "# running check_accuracy on training and test set\n",
        "train_acc, y_train, train_pred = check_accuracy(train_loader, model)\n",
        "test_acc, y_test, test_pred = check_accuracy(test_loader, model)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsjzCJUyGHaU",
        "outputId": "005522fb-9848-4ca1-f6c4-a45312a110c1"
      },
      "source": [
        "print(train_acc, test_acc)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8104, device='cuda:0') tensor(0.7264, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ACg9G0g5UZ_",
        "outputId": "163f625f-15b0-430a-f540-cf9d6a3c04b6"
      },
      "source": [
        "# The reason test_pred has two tensors is because it is 106 data, and 64 is batch size, so it happens in 1 batch of 64 and 1 batch of 42\n",
        "test_pred"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1je8nVNhAyhM"
      },
      "source": [
        "# consider if change batch size\n",
        "if (device == torch.device('cuda')):\n",
        "  test_pred = test_pred[0].to(device=torch.device('cpu'))\n",
        "  y_test = y_test[0].to(device=torch.device('cpu'))\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhdqINChHEOW"
      },
      "source": [
        "# 256 batch size means no need to concatenate\n",
        "\n",
        "# test_pred = torch.cat(test_pred) # \n",
        "# y_test = torch.cat(y_test) # move tensor y_test to cpu for concatenation, gpu can't do that computationally"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFxWaU-x3msW"
      },
      "source": [
        "conf_mat = confusion_matrix(y_test, test_pred)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFfxcVS9I6ID"
      },
      "source": [
        "tn, fp, fn, tp = conf_mat.ravel()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or_CoFhyI86d",
        "outputId": "734cfafb-bd56-4e9f-ff83-3cf93c35ccd4"
      },
      "source": [
        "tp, fn, tn, fp"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 12, 39, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgF5DH6YJ4En"
      },
      "source": [
        "True positive + false negative = number of PD patients\n",
        "\n",
        "True negative + false positive = number of control patients"
      ]
    }
  ]
}