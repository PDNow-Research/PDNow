{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Numerical.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/yH32tD+1x7YFXQlkCiWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PDNow-Research/PDNow/blob/main/HandPD/NeuralNets/NN_Numerical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGertFcjmEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5e587d-2721-4c44-90e7-2af596159df0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9pOrBx_4cC"
      },
      "source": [
        "We are going to take text-based features and apply a simple, fully-connected neural network to them. Atually, let's use images - that's what the tutorial does. Let's only consider Meander for the time being."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eF1D-LjzNr"
      },
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Image Reading\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Other ML Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Torch General\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn # loss functions, neural network type (convolutional, linear, etc.)\n",
        "import torch.optim as optim # optimization functions (sgd)\n",
        "import torch.nn.functional as F # functions without parameters - activation functions (Relu, etc.) (also included in nn package, could use, but functional package is \"better\")\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets # torch has a LOT LOT LOT of standard datasets (ImageNet, MNIST, etc.)\n",
        "import torchvision.transforms as transforms # transformations for dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # PyTorch train test split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvwBQmamlFeR"
      },
      "source": [
        "First to load the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7oC7YSPkdtG"
      },
      "source": [
        "## Set Device + Init Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJcm8-PNalT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b25c5a34-9e37-4498-be82-c60562ed6d9f"
      },
      "source": [
        "# Device set \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # google colab provides cuda gpu\n",
        "print (device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3nthTPetEQf"
      },
      "source": [
        "# Hyperparams\n",
        "input_size = 9 # size of 1 row of data\n",
        "num_classes = 2 # which is output_size\n",
        "\n",
        "# tunables\n",
        "test_size = 0.2\n",
        "learning_rate = 0.01\n",
        "batch_size = 256\n",
        "num_epochs = 150\n",
        "seed = 0 # just random state to start at"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FL-1eHknDM"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5gu2CV-kn8"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QSHyNkXuZAX"
      },
      "source": [
        "# Fix Duplicates\n",
        "# Our duplicates are 5, 23, 31 patient_ids\n",
        "def fix_duplicate_ids(df, patient_ids, exam_ids, new_ids):\n",
        "\n",
        "  df = df.copy()\n",
        "  \n",
        "  for i in range(len(patient_ids)): # don't need the actually patient_id numbers, but important that user knows what they are\n",
        "    df[\"ID_PATIENT\"][df[\"_ID_EXAM\"] == exam_ids[i]] = new_ids[i]\n",
        "\n",
        "  return df"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6s3QrYpvRN"
      },
      "source": [
        "def feature_normalization(df):\n",
        "\n",
        "  avg_dev = df.mad(axis = 0)\n",
        "  std_dev = df.std(axis = 0)\n",
        "\n",
        "  df = df.sub(avg_dev)\n",
        "  df = df.divide(std_dev)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTuX0ihosiD"
      },
      "source": [
        "class PDDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # Data loading\n",
        "    spiral_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewSpiral.csv')\n",
        "    meander_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewMeander.csv')\n",
        "\n",
        "    data_all = pd.concat((spiral_df, meander_df))\n",
        "    data_all = fix_duplicate_ids(data_all, [5, 23, 31], ['P25', 'P3', 'P26'], [500, 501, 502])\n",
        "\n",
        "    # Normalization\n",
        "    X = data_all[['RMS', 'MAX_BETWEEN_ET_HT', 'MIN_BETWEEN_ET_HT', 'STD_DEVIATION_ET_HT', 'MRT', 'MAX_HT', 'MIN_HT','STD_HT', 'CHANGES_FROM_NEGATIVE_TO_POSITIVE_BETWEEN_ET_HT']]\n",
        "    X = feature_normalization(X)\n",
        "    \n",
        "    # We must avoid shuffling the data now. It should stay in order all throughout the process\n",
        "    X = X.to_numpy(dtype=float)\n",
        "    y = data_all['CLASS_TYPE'].to_numpy()\n",
        "    \n",
        "    y = y - 1 # so we have labels 0 and 1, not 1 and 2\n",
        "\n",
        "    self.n_samples = data_all.shape[0]\n",
        "\n",
        "    self.x = torch.from_numpy(X).float() # creates tensor from numpy array, making it float as expected by model\n",
        "    self.y = torch.from_numpy(y).long() # y_all is numpy array too, making it a long as expected by model\n",
        "  \n",
        "  # support indexing such that dataset[i] can be used to get i-th sample\n",
        "  def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "  # to return size\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5rlj-zaatPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f93865-25a7-4508-a3b4-c76f978b42cf"
      },
      "source": [
        "dataset = PDDataset() # Meander Dataset object\n",
        "\n",
        "# Why the warning?"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOCtKHuXv33-",
        "outputId": "28f445a3-2388-4907-d36a-1e97c82bcda5"
      },
      "source": [
        "first_row = dataset[0]\n",
        "feature0, label0 = first_row\n",
        "print(feature0, label0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 7.1436,  7.8385,  3.2998, -0.1434,  4.7975,  8.7665, -0.2707,  4.8289,\n",
            "         0.8604]) tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4NmhAIIwV-",
        "outputId": "767abf1f-6c03-4092-add3-1a4c158f0bc0"
      },
      "source": [
        "len(dataset) # make sense, 264 * 2"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "528"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzYiS7yNNxBQ"
      },
      "source": [
        "### DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYxhzwoMiga"
      },
      "source": [
        "# Dataloader to load whole dataset\n",
        "# Shuffle: no shuffle should happen! We don't want to mix up the data, since patient info must correspond with the proper labels for diagnosis\n",
        "# num_workers: faster loading with multiple subprocesses simultaneously, set to 0 if error occurs when loading"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vfo8yMzBh_b"
      },
      "source": [
        "# To perform train test split, we'll use sklearn... https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, test_indices, _ , _ = train_test_split(\n",
        "    range(len(dataset)),\n",
        "    dataset.y,\n",
        "    stratify=dataset.y,\n",
        "    test_size=test_size,\n",
        "    random_state=seed\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk9e_kh9JPcR"
      },
      "source": [
        "# train_indices is indices of the training values while test_indices is indicies of the testing values. Let's split our data like such.\n",
        "\n",
        "# can I concatenate to a dataset object??? we wont worry about it right now. This is for patient level diagnosis...\n",
        "\n",
        "# generate subset based on indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "test_dataset = Subset(dataset, test_indices)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j3h00VAeRqe",
        "outputId": "369bb3e3-7334-4c2c-91f5-b931cff5c5d0"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.Subset at 0x7f00b16a3090>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NNckzyJgiR",
        "outputId": "5cb7b6c7-3eae-4151-8058-ac942d5f1e19"
      },
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(422, 106)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy29psB1Z8L"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers =2)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True, num_workers =2)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G2v9AbplQ3_"
      },
      "source": [
        "## Defining the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUNYEAhmT3Zd"
      },
      "source": [
        "ACTIVATION FUNCTION DECIDES WHAT IS SENT TO THE NEXT LAYER - IT IS between LAYERS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGjWjPnA2w3"
      },
      "source": [
        "Now to create the fully connected network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_16mfP3JkKp9"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, output_size): # input-size = 9, num_classes = 2 (PD/no PD), which is the output size for each row\n",
        "\n",
        "    super(NN, self).__init__() # initializes the NN class that we're defining\n",
        "    self.fc1 = nn.Linear(input_size, 64) # 5000 nodes - WAYY too much\n",
        "    self.dt1 = nn.Dropout(0.1, inplace=False)\n",
        "    self.fc2 = nn.Linear(64, 16)\n",
        "    self.fc3 = nn.Linear(16, output_size)\n",
        "    #self.hd1 = nn.Linear(32, hidden_size1)\n",
        "    \n",
        "    #self.hd2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "    \n",
        "\n",
        "  def forward(self, x): # run on some input x, which is the images which we run through fc1 and fc2 layers created above (and add the reLU activation function it between)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # x = F.relu(self.hd1(x))\n",
        "    x = self.dt1(x)\n",
        "    x = torch.sigmoid(self.fc2(x)) # functional library.sigmoid is deprecated\n",
        "    # x = F.relu(self.hd2(x))\n",
        "    x = F.softmax(self.fc3(x))\n",
        "    return x"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJ98iivMqS6"
      },
      "source": [
        "### Quick Test\n",
        "\n",
        "What the model should output it something of shape [264 (140 + 124), 2]. For each image, it should predict the probability of it being in class 1 or 2 and return both of those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHUZ9XHGEaVa",
        "outputId": "21d599f9-cd0c-41ec-a58c-6229fc19db5e"
      },
      "source": [
        "# input-size really refers to the size of 1 row of data.\n",
        "# batch-size is the number of rows being fed to the model at one time\n",
        "\n",
        "model = NN(9, 2) \n",
        "print (model)\n",
        "\n",
        "# 264 spiral, 264 meander images\n",
        "# 35 non PD patients, 31 PD patients, each who drew 4 spirals and 4 meanders\n",
        "x = torch.randn(64, 9) # 64 batch size, 9 x 1 is the size of 1 row of data. This is the shape of what will be fed to the model at one time. (2D array of 64 x 9)\n",
        "print (model(x).shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (fc1): Linear(in_features=9, out_features=64, bias=True)\n",
            "  (dt1): Dropout(p=0.1, inplace=False)\n",
            "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
            "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
            ")\n",
            "torch.Size([64, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiZh08qdBNUu",
        "outputId": "b78620b8-793e-4ad9-d141-2932cb4067c5"
      },
      "source": [
        "print (model(x)[0:10])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5270, 0.4730],\n",
            "        [0.5249, 0.4751],\n",
            "        [0.5353, 0.4647],\n",
            "        [0.5358, 0.4642],\n",
            "        [0.5317, 0.4683],\n",
            "        [0.5172, 0.4828],\n",
            "        [0.5367, 0.4633],\n",
            "        [0.5322, 0.4678],\n",
            "        [0.5383, 0.4617],\n",
            "        [0.5268, 0.4732]], grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTx3jhOBK8Ns"
      },
      "source": [
        "## Initialize Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-SEtZyLAUE"
      },
      "source": [
        "model = NN(input_size = input_size, output_size = num_classes).to(device) # input-size??"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUS61pUBLFvk"
      },
      "source": [
        "# Loss + Optimizer\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate) # optimizer function"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO7z25t4KIWY"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "CCNdQnCYKKxk",
        "outputId": "a7f5719c-f288-40ba-b9e2-31a015d6c9de"
      },
      "source": [
        "# epochs: number of times network sees images. 1 epoch - seen all images once\n",
        "loss_values = [] * 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader): # parts of the train_loader, (data,targets) in tuple together, batch_idx there before\n",
        "        \n",
        "        # Get data to cuda (that's our device, if it's possible)\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # forward propagation\n",
        "        scores = model(data)\n",
        "\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # backward propagation\n",
        "        optimizer.zero_grad() # set all gradients to 0 for each batch so it doesnt store calculation from previous batch\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_values.append(loss) # loss after each epoch\n",
        "\n",
        "plt.plot(np.array(loss_values), 'r')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f00b48b8890>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBJOAYXNn38"
      },
      "source": [
        "## Check Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgWgMQdNpMe"
      },
      "source": [
        "def check_accuracy(loader, model):\n",
        "  \"\"\" if loader.dataset.train: # if this is true, then it is loading and checking training data\n",
        "    print ('Checking accuracy on training data')\n",
        "  else: \n",
        "    print ('Checking accuracy on testing data')\n",
        "\n",
        "  Appears to be error with this code  \n",
        "  \"\"\"\n",
        "\n",
        "  # initializing\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  y_pred = [] * 1\n",
        "  y_true = [] * 1\n",
        "\n",
        "  model.eval() # why this specifically?\n",
        "\n",
        "  with torch.no_grad(): # so we don't have to compute gradients for accuracy\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device)\n",
        "      y = y.to(device=device)\n",
        "\n",
        "      y_true.append(y)\n",
        "      \n",
        "      # reshape useless here\n",
        "      # x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "      scores = model(x)\n",
        "\n",
        "      # print (scores) # this returns 6 arrays of 64 x 2 and 1 of 38 x 2\n",
        "\n",
        "      # _, is don't store this part in anything\n",
        "      _, prediction = scores.max(1) # gives us index of maximum score value (max along second dimension, reason for the 1) in predictions variable each time\n",
        "      \n",
        "      y_pred.append(prediction)\n",
        "      \n",
        "      num_correct += (prediction == y).sum()\n",
        "      num_samples += prediction.size(0)\n",
        "\n",
        "  model.train()\n",
        "  acc = num_correct/num_samples\n",
        "  return acc, y_true, y_pred"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va66YK0T5Kin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7935c83f-35ac-4387-d05d-3b39d9545d9a"
      },
      "source": [
        "# running check_accuracy on training and test set\n",
        "train_acc, y_train, train_pred = check_accuracy(train_loader, model)\n",
        "test_acc, y_test, test_pred = check_accuracy(test_loader, model)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsjzCJUyGHaU",
        "outputId": "005522fb-9848-4ca1-f6c4-a45312a110c1"
      },
      "source": [
        "print(train_acc, test_acc)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8104, device='cuda:0') tensor(0.7264, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ACg9G0g5UZ_",
        "outputId": "163f625f-15b0-430a-f540-cf9d6a3c04b6"
      },
      "source": [
        "# The reason test_pred has two tensors is because it is 106 data, and 64 is batch size, so it happens in 1 batch of 64 and 1 batch of 42\n",
        "test_pred"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "         0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "         1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "         1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "         0, 0, 0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1je8nVNhAyhM"
      },
      "source": [
        "# consider if change batch size\n",
        "if (device == torch.device('cuda')):\n",
        "  test_pred = test_pred[0].to(device=torch.device('cpu'))\n",
        "  y_test = y_test[0].to(device=torch.device('cpu'))\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhdqINChHEOW"
      },
      "source": [
        "# 256 batch size means no need to concatenate\n",
        "\n",
        "# test_pred = torch.cat(test_pred) # \n",
        "# y_test = torch.cat(y_test) # move tensor y_test to cpu for concatenation, gpu can't do that computationally"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFxWaU-x3msW"
      },
      "source": [
        "conf_mat = confusion_matrix(y_test, test_pred)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFfxcVS9I6ID"
      },
      "source": [
        "tn, fp, fn, tp = conf_mat.ravel()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or_CoFhyI86d",
        "outputId": "734cfafb-bd56-4e9f-ff83-3cf93c35ccd4"
      },
      "source": [
        "tp, fn, tn, fp"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 12, 39, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgF5DH6YJ4En"
      },
      "source": [
        "True positive + false negative = number of PD patients\n",
        "\n",
        "True negative + false positive = number of control patients"
      ]
    }
  ]
}