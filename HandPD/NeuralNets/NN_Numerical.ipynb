{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Numerical.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2gu5Ou1aJnyAaayb4rKrU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PDNow-Research/PDNow/blob/main/HandPD/NeuralNets/NN_Numerical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGertFcjmEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94721028-0d82-4991-a35a-d5ce0db89acf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9pOrBx_4cC"
      },
      "source": [
        "We are going to take text-based features and apply a simple, fully-connected neural network to them. Atually, let's use images - that's what the tutorial does. Let's only consider Meander for the time being."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eF1D-LjzNr"
      },
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Image Reading\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Other ML Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Torch General\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn # loss functions, neural network type (convolutional, linear, etc.)\n",
        "import torch.optim as optim # optimization functions (sgd)\n",
        "import torch.nn.functional as F # functions without parameters - activation functions (Relu, etc.) (also included in nn package, could use, but functional package is \"better\")\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets # torch has a LOT LOT LOT of standard datasets (ImageNet, MNIST, etc.)\n",
        "import torchvision.transforms as transforms # transformations for dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # PyTorch train test split"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvwBQmamlFeR"
      },
      "source": [
        "First to load the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FL-1eHknDM"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5gu2CV-kn8"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QSHyNkXuZAX"
      },
      "source": [
        "# Fix Duplicates\n",
        "# Our duplicates are 5, 23, 31 patient_ids\n",
        "def fix_duplicate_ids(df, patient_ids, exam_ids, new_ids):\n",
        "\n",
        "  df = df.copy()\n",
        "  \n",
        "  for i in range(len(patient_ids)): # don't need the actually patient_id numbers, but important that user knows what they are\n",
        "    df[\"ID_PATIENT\"][df[\"_ID_EXAM\"] == exam_ids[i]] = new_ids[i]\n",
        "\n",
        "  return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6s3QrYpvRN"
      },
      "source": [
        "def feature_normalization(df):\n",
        "\n",
        "  avg_dev = df.mad(axis = 0)\n",
        "  std_dev = df.std(axis = 0)\n",
        "\n",
        "  df = df.sub(avg_dev)\n",
        "  df = df.divide(std_dev)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTuX0ihosiD"
      },
      "source": [
        "class PDDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # Data loading\n",
        "    spiral_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewSpiral.csv')\n",
        "    meander_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewMeander.csv')\n",
        "\n",
        "    data_all = pd.concat((spiral_df, meander_df))\n",
        "    data_all = fix_duplicate_ids(data_all, [5, 23, 31], ['P25', 'P3', 'P26'], [500, 501, 502])\n",
        "\n",
        "    # Normalization\n",
        "    X = data_all[['RMS', 'MAX_BETWEEN_ET_HT', 'MIN_BETWEEN_ET_HT', 'STD_DEVIATION_ET_HT', 'MRT', 'MAX_HT', 'MIN_HT','STD_HT', 'CHANGES_FROM_NEGATIVE_TO_POSITIVE_BETWEEN_ET_HT']]\n",
        "    X = feature_normalization(X)\n",
        "    \n",
        "    # We must avoid shuffling the data now. It should stay in order all throughout the process\n",
        "    X = X.to_numpy(dtype=float)\n",
        "    y = data_all['CLASS_TYPE'].to_numpy()\n",
        "    \n",
        "    y = y - 1 # so we have labels 0 and 1, not 1 and 2\n",
        "\n",
        "    self.n_samples = data_all.shape[0]\n",
        "\n",
        "    self.x = torch.from_numpy(X).float() # creates tensor from numpy array, making it float as expected by model\n",
        "    self.y = torch.from_numpy(y).long() # y_all is numpy array too, making it a long as expected by model\n",
        "  \n",
        "  # support indexing such that dataset[i] can be used to get i-th sample\n",
        "  def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "  # to return size\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5rlj-zaatPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02522cf6-7989-410f-e637-26443cbff258"
      },
      "source": [
        "dataset = PDDataset() # Meander Dataset object\n",
        "\n",
        "# Why the warning?"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOCtKHuXv33-",
        "outputId": "5b8939a8-a45e-4840-bd7a-9353e77ede65"
      },
      "source": [
        "first_row = dataset[0]\n",
        "feature0, label0 = first_row\n",
        "print(feature0, label0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 7.1436,  7.8385,  3.2998, -0.1434,  4.7975,  8.7665, -0.2707,  4.8289,\n",
            "         0.8604]) tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4NmhAIIwV-",
        "outputId": "e95541d1-75e8-4291-b7f7-934468c01458"
      },
      "source": [
        "len(dataset) # make sense, 264 * 2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "528"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G2v9AbplQ3_"
      },
      "source": [
        "## Defining the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUNYEAhmT3Zd"
      },
      "source": [
        "ACTIVATION FUNCTION DECIDES WHAT IS SENT TO THE NEXT LAYER - IT IS between LAYERS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGjWjPnA2w3"
      },
      "source": [
        "Now to create the fully connected network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_16mfP3JkKp9"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, output_size): # input-size = 9, num_classes = 2 (PD/no PD), which is the output size for each row\n",
        "    hidden_size1 = 16 # hyperparam\n",
        "    hidden_size2 = 8\n",
        "\n",
        "    super(NN, self).__init__() # initializes the NN class that we're defining\n",
        "    self.fc1 = nn.Linear(input_size, 32) # 5000 nodes - WAYY too much\n",
        "    self.hd1 = nn.Linear(32, hidden_size1)\n",
        "    self.dt1 = nn.Dropout(0.01, inplace=False)\n",
        "    self.hd2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "    self.fc2 = nn.Linear(hidden_size2, output_size)\n",
        "\n",
        "  def forward(self, x): # run on some input x, which is the images which we run through fc1 and fc2 layers created above (and add the reLU activation function it between)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(self.hd1(x))\n",
        "    x = F.relu(self.dt1(x))\n",
        "    x = F.relu(self.hd2(x))\n",
        "    x = F.sigmoid(self.fc2(x))\n",
        "    return x"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJ98iivMqS6"
      },
      "source": [
        "### Quick Test\n",
        "\n",
        "What the model should output it something of shape [264 (140 + 124), 2]. For each image, it should predict the probability of it being in class 1 or 2 and return both of those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7oC7YSPkdtG"
      },
      "source": [
        "## Set Device + Init Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJcm8-PNalT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63760093-b13a-4619-8627-7e841f6b21ff"
      },
      "source": [
        "# Device set \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # google colab provides cuda gpu\n",
        "print (device)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3nthTPetEQf"
      },
      "source": [
        "# Hyperparams\n",
        "input_size = 9 # size of 1 row of data\n",
        "num_classes = 2 # which is output_size\n",
        "\n",
        "# tunables\n",
        "test_size = 0.2\n",
        "learning_rate = 0.001\n",
        "batch_size = 256\n",
        "num_epochs = 128\n",
        "seed = 0 # just random state to start at"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHUZ9XHGEaVa",
        "outputId": "bb2e7aa0-2519-4e5c-e625-2c98c4b61131"
      },
      "source": [
        "# input-size really refers to the size of 1 row of data.\n",
        "# batch-size is the number of rows being fed to the model at one time\n",
        "\n",
        "model = NN(9, 2) \n",
        "print (model)\n",
        "\n",
        "# 264 spiral, 264 meander images\n",
        "# 35 non PD patients, 31 PD patients, each who drew 4 spirals and 4 meanders\n",
        "x = torch.randn(64, 9) # 64 batch size, 9 x 1 is the size of 1 row of data. This is the shape of what will be fed to the model at one time. (2D array of 64 x 9)\n",
        "print (model(x).shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (fc1): Linear(in_features=9, out_features=32, bias=True)\n",
            "  (hd1): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (dt1): Dropout(p=0.01, inplace=False)\n",
            "  (hd2): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (fc2): Linear(in_features=8, out_features=2, bias=True)\n",
            ")\n",
            "torch.Size([64, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzYiS7yNNxBQ"
      },
      "source": [
        "## DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYxhzwoMiga"
      },
      "source": [
        "# Dataloader to load whole dataset\n",
        "# Shuffle: no shuffle should happen! We don't want to mix up the data, since patient info must correspond with the proper labels for diagnosis\n",
        "# num_workers: faster loading with multiple subprocesses simultaneously, set to 0 if error occurs when loading"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vfo8yMzBh_b"
      },
      "source": [
        "# To perform train test split, we'll use sklearn... https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
        "\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, test_indices, _ , _ = train_test_split(\n",
        "    range(len(dataset)),\n",
        "    dataset.y,\n",
        "    stratify=dataset.y,\n",
        "    test_size=test_size,\n",
        "    random_state=seed\n",
        ")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk9e_kh9JPcR"
      },
      "source": [
        "# train_indices is indices of the training values while test_indices is indicies of the testing values. Let's split our data like such.\n",
        "\n",
        "# can I concatenate to a dataset object??? we wont worry about it right now. This is for patient level diagnosis...\n",
        "\n",
        "# generate subset based on indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "test_dataset = Subset(dataset, test_indices)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j3h00VAeRqe",
        "outputId": "e5e97bcb-8ea8-4b74-aa1c-c3962b29af4b"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.Subset at 0x7f88b52cd0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NNckzyJgiR",
        "outputId": "c4eed758-4494-4153-cc03-1ce38796f7f7"
      },
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(422, 106)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy29psB1Z8L"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers =2)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True, num_workers =2)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTx3jhOBK8Ns"
      },
      "source": [
        "## Initialize Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-SEtZyLAUE"
      },
      "source": [
        "model = NN(input_size = input_size, output_size = num_classes).to(device) # input-size??"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUS61pUBLFvk"
      },
      "source": [
        "# Loss + Optimizer\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate) # optimizer function"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO7z25t4KIWY"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "CCNdQnCYKKxk",
        "outputId": "a0517ed0-951a-4d3d-d810-a0a4bd9d3ac3"
      },
      "source": [
        "# epochs: number of times network sees images. 1 epoch - seen all images once\n",
        "loss_values = [] * 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader): # parts of the train_loader, (data,targets) in tuple together, batch_idx there before\n",
        "        \n",
        "        # Get data to cuda (that's our device, if it's possible)\n",
        "        data = data.to(device=device)\n",
        "\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # print (data.shape)\n",
        "\n",
        "        # Get to correct shape, which is a 2D matrix of 64 x 9, because model(x) of shape should be 64 x 2?\n",
        "        # Data is already in this correct shape, examine why?\n",
        "        # data = data.reshape(64, 9])\n",
        "\n",
        "        # by looking at this, we see we have 7 batches: 6 of size 64, 1 of size 38.\n",
        "\n",
        "        # forward propagation\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # backward propagation\n",
        "        optimizer.zero_grad() # set all gradients to 0 for each batch so it doesnt store calculation from previous batch\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_values.append(loss) # loss after each epoch\n",
        "\n",
        "plt.plot(np.array(loss_values), 'r')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f88b5261190>]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBJOAYXNn38"
      },
      "source": [
        "## Check Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgWgMQdNpMe"
      },
      "source": [
        "def check_accuracy(loader, model):\n",
        "  \"\"\" if loader.dataset.train: # if this is true, then it is loading and checking training data\n",
        "    print ('Checking accuracy on training data')\n",
        "  else: \n",
        "    print ('Checking accuracy on testing data')\n",
        "\n",
        "  Appears to be error with this code  \n",
        "  \"\"\"\n",
        "\n",
        "  # initializing\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  y_pred = [] * 1\n",
        "  y_true = [] * 1\n",
        "\n",
        "  model.eval() # why this specifically?\n",
        "\n",
        "  with torch.no_grad(): # so we don't have to compute gradients for accuracy\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device)\n",
        "      y = y.to(device=device)\n",
        "\n",
        "      y_true.append(y)\n",
        "      \n",
        "      # reshape useless here\n",
        "      # x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "      scores = model(x)\n",
        "\n",
        "      # print (scores) # this returns 6 arrays of 64 x 2 and 1 of 38 x 2\n",
        "\n",
        "      # _, is don't store this part in anything\n",
        "      _, prediction = scores.max(1) # gives us index of maximum score value (max along second dimension, reason for the 1) in predictions variable each time\n",
        "      \n",
        "      y_pred.append(prediction)\n",
        "      \n",
        "      num_correct += (prediction == y).sum()\n",
        "      num_samples += prediction.size(0)\n",
        "\n",
        "  model.train()\n",
        "  acc = num_correct/num_samples\n",
        "  return acc, y_true, y_pred"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va66YK0T5Kin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7f8389-f836-4853-9c45-f75932831931"
      },
      "source": [
        "# running check_accuracy on training and test set\n",
        "train_acc, y_train, train_pred = check_accuracy(train_loader, model)\n",
        "test_acc, y_test, test_pred = check_accuracy(test_loader, model)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsjzCJUyGHaU",
        "outputId": "e85ae9e1-db3d-4dec-8b00-6d54134c3777"
      },
      "source": [
        "print(train_acc, test_acc)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7773) tensor(0.7358)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ACg9G0g5UZ_",
        "outputId": "cba23295-e812-4ad5-b97a-84deb178a0b3"
      },
      "source": [
        "# The reason test_pred has two tensors is because it is 106 data, and 64 is batch size, so it happens in 1 batch of 64 and 1 batch of 42\n",
        "test_pred"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "         1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
              " tensor([0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1])]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhdqINChHEOW"
      },
      "source": [
        "test_pred = torch.cat(test_pred)\n",
        "y_test = torch.cat(y_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFxWaU-x3msW"
      },
      "source": [
        "conf_mat = confusion_matrix(y_test, test_pred)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFfxcVS9I6ID"
      },
      "source": [
        "tn, fp, fn, tp = conf_mat.ravel()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or_CoFhyI86d",
        "outputId": "a5fe854e-6813-4e7a-81c8-e0ec51a80310"
      },
      "source": [
        "tp, fn, tn, fp"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43, 7, 35, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgF5DH6YJ4En"
      },
      "source": [
        "True positive + false negative = number of PD patients\n",
        "\n",
        "True negative + false positive = number of control patients"
      ]
    }
  ]
}