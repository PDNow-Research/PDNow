{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Numerical.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCajBrLZDAM3BemboU9Jps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PDNow-Research/PDNow/blob/main/HandPD/NeuralNets/NN_Numerical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGertFcjmEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8bc5d9-cf56-458b-ee99-01b50ea6063c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9pOrBx_4cC"
      },
      "source": [
        "We are going to take text-based features and apply a simple, fully-connected neural network to them. Atually, let's use images - that's what the tutorial does. Let's only consider Meander for the time being."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eF1D-LjzNr"
      },
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Image Reading\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Other ML Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Torch General\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn # loss functions, neural network type (convolutional, linear, etc.)\n",
        "import torch.optim as optim # optimization functions (sgd)\n",
        "import torch.nn.functional as F # functions without parameters - activation functions (Relu, etc.) (also included in nn package, could use, but functional package is \"better\")\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets # torch has a LOT LOT LOT of standard datasets (ImageNet, MNIST, etc.)\n",
        "import torchvision.transforms as transforms # transformations for dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # PyTorch train test split"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvwBQmamlFeR"
      },
      "source": [
        "First to load the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FL-1eHknDM"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5gu2CV-kn8"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QSHyNkXuZAX"
      },
      "source": [
        "# Fix Duplicates\n",
        "# Our duplicates are 5, 23, 31 patient_ids\n",
        "def fix_duplicate_ids(df, patient_ids, exam_ids, new_ids):\n",
        "\n",
        "  df = df.copy()\n",
        "  \n",
        "  for i in range(len(patient_ids)): # don't need the actually patient_id numbers, but important that user knows what they are\n",
        "    df[\"ID_PATIENT\"][df[\"_ID_EXAM\"] == exam_ids[i]] = new_ids[i]\n",
        "\n",
        "  return df"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6s3QrYpvRN"
      },
      "source": [
        "def feature_normalization(df):\n",
        "\n",
        "  avg_dev = df.mad(axis = 0)\n",
        "  std_dev = df.std(axis = 0)\n",
        "\n",
        "  df = df.sub(avg_dev)\n",
        "  df = df.divide(std_dev)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTuX0ihosiD"
      },
      "source": [
        "class PDDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # Data loading\n",
        "    spiral_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewSpiral.csv')\n",
        "    meander_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewMeander.csv')\n",
        "\n",
        "    data_all = pd.concat((spiral_df, meander_df))\n",
        "    data_all = fix_duplicate_ids(data_all, [5, 23, 31], ['P25', 'P3', 'P26'], [500, 501, 502])\n",
        "\n",
        "    # Normalization\n",
        "    X = data_all[['RMS', 'MAX_BETWEEN_ET_HT', 'MIN_BETWEEN_ET_HT', 'STD_DEVIATION_ET_HT', 'MRT', 'MAX_HT', 'MIN_HT','STD_HT', 'CHANGES_FROM_NEGATIVE_TO_POSITIVE_BETWEEN_ET_HT']]\n",
        "    X = feature_normalization(X)\n",
        "    \n",
        "    # We must avoid shuffling the data now. It should stay in order all throughout the process\n",
        "    X = X.to_numpy(dtype=float)\n",
        "    y = data_all['CLASS_TYPE'].to_numpy()\n",
        "    \n",
        "    y = y - 1 # so we have labels 0 and 1, not 1 and 2\n",
        "\n",
        "    self.n_samples = data_all.shape[0]\n",
        "\n",
        "    self.x = torch.from_numpy(X).float() # creates tensor from numpy array, making it float as expected by model\n",
        "    self.y = torch.from_numpy(y).long() # y_all is numpy array too, making it a long as expected by model\n",
        "  \n",
        "  # support indexing such that dataset[i] can be used to get i-th sample\n",
        "  def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "  # to return size\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5rlj-zaatPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f053d91-1d20-47d4-cf6b-4110619c624f"
      },
      "source": [
        "dataset = PDDataset() # Meander Dataset object\n",
        "\n",
        "# Why the warning?"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOCtKHuXv33-",
        "outputId": "3c357a1f-3187-490b-c7c3-89d15f1f2ed3"
      },
      "source": [
        "first_row = dataset[0]\n",
        "feature0, label0 = first_row\n",
        "print(feature0, label0)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 7.1436,  7.8385,  3.2998, -0.1434,  4.7975,  8.7665, -0.2707,  4.8289,\n",
            "         0.8604]) tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4NmhAIIwV-",
        "outputId": "c9a177a5-2bbb-4cfe-a6e6-ed713cd53fac"
      },
      "source": [
        "len(dataset) # make sense, 264 * 2"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "528"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzYiS7yNNxBQ"
      },
      "source": [
        "### DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYxhzwoMiga"
      },
      "source": [
        "# Dataloader to load whole dataset\n",
        "# Shuffle: no shuffle should happen! We don't want to mix up the data, since patient info must correspond with the proper labels for diagnosis\n",
        "# num_workers: faster loading with multiple subprocesses simultaneously, set to 0 if error occurs when loading"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vfo8yMzBh_b"
      },
      "source": [
        "# To perform train test split, we'll use sklearn... https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
        "\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, test_indices, _ , _ = train_test_split(\n",
        "    range(len(dataset)),\n",
        "    dataset.y,\n",
        "    stratify=dataset.y,\n",
        "    test_size=test_size,\n",
        "    random_state=seed\n",
        ")"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk9e_kh9JPcR"
      },
      "source": [
        "# train_indices is indices of the training values while test_indices is indicies of the testing values. Let's split our data like such.\n",
        "\n",
        "# can I concatenate to a dataset object??? we wont worry about it right now. This is for patient level diagnosis...\n",
        "\n",
        "# generate subset based on indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "test_dataset = Subset(dataset, test_indices)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j3h00VAeRqe",
        "outputId": "c98c8dfc-7e59-4013-94ee-728d558d0b32"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.Subset at 0x7ff154fb74d0>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NNckzyJgiR",
        "outputId": "b4d905cd-f1fd-4869-927d-6c7fae414e94"
      },
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(396, 132)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy29psB1Z8L"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers =2)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True, num_workers =2)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G2v9AbplQ3_"
      },
      "source": [
        "## Defining the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUNYEAhmT3Zd"
      },
      "source": [
        "ACTIVATION FUNCTION DECIDES WHAT IS SENT TO THE NEXT LAYER - IT IS between LAYERS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGjWjPnA2w3"
      },
      "source": [
        "Now to create the fully connected network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_16mfP3JkKp9"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, output_size): # input-size = 9, num_classes = 2 (PD/no PD), which is the output size for each row\n",
        "\n",
        "    super(NN, self).__init__() # initializes the NN class that we're defining\n",
        "    self.fc1 = nn.Linear(input_size, 64) # 5000 nodes - WAYY too much\n",
        "    self.dt1 = nn.Dropout(0.1, inplace=False)\n",
        "    self.fc2 = nn.Linear(64, 16)\n",
        "    self.fc3 = nn.Linear(16, output_size)\n",
        "    #self.hd1 = nn.Linear(32, hidden_size1)\n",
        "    \n",
        "    #self.hd2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "    \n",
        "\n",
        "  def forward(self, x): # run on some input x, which is the images which we run through fc1 and fc2 layers created above (and add the reLU activation function it between)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # x = F.relu(self.hd1(x))\n",
        "    x = self.dt1(x)\n",
        "    x = torch.sigmoid(self.fc2(x)) # functional library.sigmoid is deprecated\n",
        "    # x = F.relu(self.hd2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJ98iivMqS6"
      },
      "source": [
        "### Quick Test\n",
        "\n",
        "What the model should output it something of shape [264 (140 + 124), 2]. For each image, it should predict the probability of it being in class 1 or 2 and return both of those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7oC7YSPkdtG"
      },
      "source": [
        "## Set Device + Init Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJcm8-PNalT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab3d477-8e46-4813-8644-d72c7833be71"
      },
      "source": [
        "# Device set \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # google colab provides cuda gpu\n",
        "print (device)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3nthTPetEQf"
      },
      "source": [
        "# Hyperparams\n",
        "input_size = 9 # size of 1 row of data\n",
        "num_classes = 2 # which is output_size\n",
        "\n",
        "# tunables\n",
        "test_size = 0.25\n",
        "learning_rate = 0.1\n",
        "batch_size = 256\n",
        "num_epochs = 500\n",
        "seed = 0 # just random state to start at"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHUZ9XHGEaVa",
        "outputId": "f8d59e80-85b4-4f0a-e8f4-daaa8b834f4b"
      },
      "source": [
        "# input-size really refers to the size of 1 row of data.\n",
        "# batch-size is the number of rows being fed to the model at one time\n",
        "\n",
        "model = NN(9, 2) \n",
        "print (model)\n",
        "\n",
        "# 264 spiral, 264 meander images\n",
        "# 35 non PD patients, 31 PD patients, each who drew 4 spirals and 4 meanders\n",
        "x = torch.randn(64, 9) # 64 batch size, 9 x 1 is the size of 1 row of data. This is the shape of what will be fed to the model at one time. (2D array of 64 x 9)\n",
        "print (model(x).shape)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (fc1): Linear(in_features=9, out_features=64, bias=True)\n",
            "  (dt1): Dropout(p=0.1, inplace=False)\n",
            "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
            "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
            ")\n",
            "torch.Size([64, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTx3jhOBK8Ns"
      },
      "source": [
        "## Initialize Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-SEtZyLAUE"
      },
      "source": [
        "model = NN(input_size = input_size, output_size = num_classes).to(device) # input-size??"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUS61pUBLFvk"
      },
      "source": [
        "# Loss + Optimizer\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate) # optimizer function"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO7z25t4KIWY"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "CCNdQnCYKKxk",
        "outputId": "fc825bed-049b-4945-95c7-ad3a7f3e2784"
      },
      "source": [
        "# epochs: number of times network sees images. 1 epoch - seen all images once\n",
        "loss_values = [] * 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader): # parts of the train_loader, (data,targets) in tuple together, batch_idx there before\n",
        "        \n",
        "        # Get data to cuda (that's our device, if it's possible)\n",
        "        data = data.to(device=device)\n",
        "\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # print (data.shape)\n",
        "\n",
        "        # Get to correct shape, which is a 2D matrix of 64 x 9, because model(x) of shape should be 64 x 2?\n",
        "        # Data is already in this correct shape, examine why?\n",
        "        # data = data.reshape(64, 9])\n",
        "\n",
        "        # by looking at this, we see we have 7 batches: 6 of size 64, 1 of size 38.\n",
        "\n",
        "        # forward propagation\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # backward propagation\n",
        "        optimizer.zero_grad() # set all gradients to 0 for each batch so it doesnt store calculation from previous batch\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_values.append(loss) # loss after each epoch\n",
        "\n",
        "plt.plot(np.array(loss_values), 'r')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff154ee3f10>]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBJOAYXNn38"
      },
      "source": [
        "## Check Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgWgMQdNpMe"
      },
      "source": [
        "def check_accuracy(loader, model):\n",
        "  \"\"\" if loader.dataset.train: # if this is true, then it is loading and checking training data\n",
        "    print ('Checking accuracy on training data')\n",
        "  else: \n",
        "    print ('Checking accuracy on testing data')\n",
        "\n",
        "  Appears to be error with this code  \n",
        "  \"\"\"\n",
        "\n",
        "  # initializing\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  y_pred = [] * 1\n",
        "  y_true = [] * 1\n",
        "\n",
        "  model.eval() # why this specifically?\n",
        "\n",
        "  with torch.no_grad(): # so we don't have to compute gradients for accuracy\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device)\n",
        "      y = y.to(device=device)\n",
        "\n",
        "      y_true.append(y)\n",
        "      \n",
        "      # reshape useless here\n",
        "      # x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "      scores = model(x)\n",
        "\n",
        "      # print (scores) # this returns 6 arrays of 64 x 2 and 1 of 38 x 2\n",
        "\n",
        "      # _, is don't store this part in anything\n",
        "      _, prediction = scores.max(1) # gives us index of maximum score value (max along second dimension, reason for the 1) in predictions variable each time\n",
        "      \n",
        "      y_pred.append(prediction)\n",
        "      \n",
        "      num_correct += (prediction == y).sum()\n",
        "      num_samples += prediction.size(0)\n",
        "\n",
        "  model.train()\n",
        "  acc = num_correct/num_samples\n",
        "  return acc, y_true, y_pred"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va66YK0T5Kin"
      },
      "source": [
        "# running check_accuracy on training and test set\n",
        "train_acc, y_train, train_pred = check_accuracy(train_loader, model)\n",
        "test_acc, y_test, test_pred = check_accuracy(test_loader, model)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsjzCJUyGHaU",
        "outputId": "c7752c29-b208-4c3a-a9a6-1290161ff59a"
      },
      "source": [
        "print(train_acc, test_acc)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7727, device='cuda:0') tensor(0.6515, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ACg9G0g5UZ_",
        "outputId": "cd4f216a-eaeb-45ab-877f-3a3e4e777879"
      },
      "source": [
        "# The reason test_pred has two tensors is because it is 106 data, and 64 is batch size, so it happens in 1 batch of 64 and 1 batch of 42\n",
        "test_pred"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "         0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "         1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
              "         1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "         0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "         0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1je8nVNhAyhM"
      },
      "source": [
        "# consider if change batch size\n",
        "if (device == torch.device('cuda')):\n",
        "  test_pred = test_pred[0].to(device=cpu_device)\n",
        "  y_test = y_test[0].to(device=cpu_device)\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhdqINChHEOW"
      },
      "source": [
        "# 256 batch size means no need to concatenate\n",
        "\n",
        "# test_pred = torch.cat(test_pred) # \n",
        "# y_test = torch.cat(y_test) # move tensor y_test to cpu for concatenation, gpu can't do that computationally"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFxWaU-x3msW"
      },
      "source": [
        "conf_mat = confusion_matrix(y_test, test_pred)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFfxcVS9I6ID"
      },
      "source": [
        "tn, fp, fn, tp = conf_mat.ravel()"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or_CoFhyI86d",
        "outputId": "f71f70c6-0e8a-4ac0-f5e4-3ae2e79e3ceb"
      },
      "source": [
        "tp, fn, tn, fp"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 17, 41, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgF5DH6YJ4En"
      },
      "source": [
        "True positive + false negative = number of PD patients\n",
        "\n",
        "True negative + false positive = number of control patients"
      ]
    }
  ]
}