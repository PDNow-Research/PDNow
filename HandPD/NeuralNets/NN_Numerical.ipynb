{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Numerical.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBVsp3qeZhOsjW1ShucfBB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PDNow-Research/PDNow/blob/main/HandPD/NeuralNets/NN_Numerical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGertFcjmEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8bc5d9-cf56-458b-ee99-01b50ea6063c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9pOrBx_4cC"
      },
      "source": [
        "We are going to take text-based features and apply a simple, fully-connected neural network to them. Atually, let's use images - that's what the tutorial does. Let's only consider Meander for the time being."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eF1D-LjzNr"
      },
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Image Reading\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Other ML Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Torch General\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn # loss functions, neural network type (convolutional, linear, etc.)\n",
        "import torch.optim as optim # optimization functions (sgd)\n",
        "import torch.nn.functional as F # functions without parameters - activation functions (Relu, etc.) (also included in nn package, could use, but functional package is \"better\")\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets # torch has a LOT LOT LOT of standard datasets (ImageNet, MNIST, etc.)\n",
        "import torchvision.transforms as transforms # transformations for dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # PyTorch train test split"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvwBQmamlFeR"
      },
      "source": [
        "First to load the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FL-1eHknDM"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5gu2CV-kn8"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QSHyNkXuZAX"
      },
      "source": [
        "# Fix Duplicates\n",
        "# Our duplicates are 5, 23, 31 patient_ids\n",
        "def fix_duplicate_ids(df, patient_ids, exam_ids, new_ids):\n",
        "\n",
        "  df = df.copy()\n",
        "  \n",
        "  for i in range(len(patient_ids)): # don't need the actually patient_id numbers, but important that user knows what they are\n",
        "    df[\"ID_PATIENT\"][df[\"_ID_EXAM\"] == exam_ids[i]] = new_ids[i]\n",
        "\n",
        "  return df"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6s3QrYpvRN"
      },
      "source": [
        "def feature_normalization(df):\n",
        "\n",
        "  avg_dev = df.mad(axis = 0)\n",
        "  std_dev = df.std(axis = 0)\n",
        "\n",
        "  df = df.sub(avg_dev)\n",
        "  df = df.divide(std_dev)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTuX0ihosiD"
      },
      "source": [
        "class PDDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # Data loading\n",
        "    spiral_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewSpiral.csv')\n",
        "    meander_df = pd.read_csv('/content/drive/My Drive/Data/HandPD-Replication/NewMeander.csv')\n",
        "\n",
        "    data_all = pd.concat((spiral_df, meander_df))\n",
        "    data_all = fix_duplicate_ids(data_all, [5, 23, 31], ['P25', 'P3', 'P26'], [500, 501, 502])\n",
        "\n",
        "    # Normalization\n",
        "    X = data_all[['RMS', 'MAX_BETWEEN_ET_HT', 'MIN_BETWEEN_ET_HT', 'STD_DEVIATION_ET_HT', 'MRT', 'MAX_HT', 'MIN_HT','STD_HT', 'CHANGES_FROM_NEGATIVE_TO_POSITIVE_BETWEEN_ET_HT']]\n",
        "    X = feature_normalization(X)\n",
        "    \n",
        "    # We must avoid shuffling the data now. It should stay in order all throughout the process\n",
        "    X = X.to_numpy(dtype=float)\n",
        "    y = data_all['CLASS_TYPE'].to_numpy()\n",
        "    \n",
        "    y = y - 1 # so we have labels 0 and 1, not 1 and 2\n",
        "\n",
        "    self.n_samples = data_all.shape[0]\n",
        "\n",
        "    self.x = torch.from_numpy(X).float() # creates tensor from numpy array, making it float as expected by model\n",
        "    self.y = torch.from_numpy(y).long() # y_all is numpy array too, making it a long as expected by model\n",
        "  \n",
        "  # support indexing such that dataset[i] can be used to get i-th sample\n",
        "  def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "  # to return size\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5rlj-zaatPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f053d91-1d20-47d4-cf6b-4110619c624f"
      },
      "source": [
        "dataset = PDDataset() # Meander Dataset object\n",
        "\n",
        "# Why the warning?"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOCtKHuXv33-",
        "outputId": "3c357a1f-3187-490b-c7c3-89d15f1f2ed3"
      },
      "source": [
        "first_row = dataset[0]\n",
        "feature0, label0 = first_row\n",
        "print(feature0, label0)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 7.1436,  7.8385,  3.2998, -0.1434,  4.7975,  8.7665, -0.2707,  4.8289,\n",
            "         0.8604]) tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4NmhAIIwV-",
        "outputId": "c9a177a5-2bbb-4cfe-a6e6-ed713cd53fac"
      },
      "source": [
        "len(dataset) # make sense, 264 * 2"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "528"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzYiS7yNNxBQ"
      },
      "source": [
        "### DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYxhzwoMiga"
      },
      "source": [
        "# Dataloader to load whole dataset\n",
        "# Shuffle: no shuffle should happen! We don't want to mix up the data, since patient info must correspond with the proper labels for diagnosis\n",
        "# num_workers: faster loading with multiple subprocesses simultaneously, set to 0 if error occurs when loading"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vfo8yMzBh_b"
      },
      "source": [
        "# To perform train test split, we'll use sklearn... https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
        "\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, test_indices, _ , _ = train_test_split(\n",
        "    range(len(dataset)),\n",
        "    dataset.y,\n",
        "    stratify=dataset.y,\n",
        "    test_size=test_size,\n",
        "    random_state=seed\n",
        ")"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk9e_kh9JPcR"
      },
      "source": [
        "# train_indices is indices of the training values while test_indices is indicies of the testing values. Let's split our data like such.\n",
        "\n",
        "# can I concatenate to a dataset object??? we wont worry about it right now. This is for patient level diagnosis...\n",
        "\n",
        "# generate subset based on indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "test_dataset = Subset(dataset, test_indices)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j3h00VAeRqe",
        "outputId": "c98c8dfc-7e59-4013-94ee-728d558d0b32"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.Subset at 0x7ff154fb74d0>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NNckzyJgiR",
        "outputId": "b4d905cd-f1fd-4869-927d-6c7fae414e94"
      },
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(396, 132)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy29psB1Z8L"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers =2)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True, num_workers =2)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G2v9AbplQ3_"
      },
      "source": [
        "## Defining the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUNYEAhmT3Zd"
      },
      "source": [
        "ACTIVATION FUNCTION DECIDES WHAT IS SENT TO THE NEXT LAYER - IT IS between LAYERS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGjWjPnA2w3"
      },
      "source": [
        "Now to create the fully connected network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_16mfP3JkKp9"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, output_size): # input-size = 9, num_classes = 2 (PD/no PD), which is the output size for each row\n",
        "\n",
        "    super(NN, self).__init__() # initializes the NN class that we're defining\n",
        "    self.fc1 = nn.Linear(input_size, 64) # 5000 nodes - WAYY too much\n",
        "    self.dt1 = nn.Dropout(0.1, inplace=False)\n",
        "    self.fc2 = nn.Linear(64, 16)\n",
        "    self.fc3 = nn.Linear(16, output_size)\n",
        "    #self.hd1 = nn.Linear(32, hidden_size1)\n",
        "    \n",
        "    #self.hd2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "    \n",
        "\n",
        "  def forward(self, x): # run on some input x, which is the images which we run through fc1 and fc2 layers created above (and add the reLU activation function it between)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # x = F.relu(self.hd1(x))\n",
        "    x = self.dt1(x)\n",
        "    x = torch.sigmoid(self.fc2(x)) # functional library.sigmoid is deprecated\n",
        "    # x = F.relu(self.hd2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJ98iivMqS6"
      },
      "source": [
        "### Quick Test\n",
        "\n",
        "What the model should output it something of shape [264 (140 + 124), 2]. For each image, it should predict the probability of it being in class 1 or 2 and return both of those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7oC7YSPkdtG"
      },
      "source": [
        "## Set Device + Init Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJcm8-PNalT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d49add4-5354-43db-cefc-25e347ec8bdb"
      },
      "source": [
        "# Device set \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # google colab provides cuda gpu\n",
        "print (device)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3nthTPetEQf"
      },
      "source": [
        "# Hyperparams\n",
        "input_size = 9 # size of 1 row of data\n",
        "num_classes = 2 # which is output_size\n",
        "\n",
        "# tunables\n",
        "test_size = 0.25\n",
        "learning_rate = 0.01\n",
        "batch_size = 256\n",
        "num_epochs = 150\n",
        "seed = 0 # just random state to start at"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHUZ9XHGEaVa",
        "outputId": "8cce96a0-4c2c-4aa1-adb3-d128f352da42"
      },
      "source": [
        "# input-size really refers to the size of 1 row of data.\n",
        "# batch-size is the number of rows being fed to the model at one time\n",
        "\n",
        "model = NN(9, 2) \n",
        "print (model)\n",
        "\n",
        "# 264 spiral, 264 meander images\n",
        "# 35 non PD patients, 31 PD patients, each who drew 4 spirals and 4 meanders\n",
        "x = torch.randn(64, 9) # 64 batch size, 9 x 1 is the size of 1 row of data. This is the shape of what will be fed to the model at one time. (2D array of 64 x 9)\n",
        "print (model(x).shape)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (fc1): Linear(in_features=9, out_features=64, bias=True)\n",
            "  (dt1): Dropout(p=0.1, inplace=False)\n",
            "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
            "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
            ")\n",
            "torch.Size([64, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTx3jhOBK8Ns"
      },
      "source": [
        "## Initialize Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-SEtZyLAUE"
      },
      "source": [
        "model = NN(input_size = input_size, output_size = num_classes).to(device) # input-size??"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUS61pUBLFvk"
      },
      "source": [
        "# Loss + Optimizer\n",
        "criterion = nn.GaussianNLLLoss() # loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate) # optimizer function"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO7z25t4KIWY"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CCNdQnCYKKxk",
        "outputId": "e2aa5f73-3bac-40fb-a78d-176fff86fd13"
      },
      "source": [
        "# epochs: number of times network sees images. 1 epoch - seen all images once\n",
        "loss_values = [] * 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader): # parts of the train_loader, (data,targets) in tuple together, batch_idx there before\n",
        "        \n",
        "        # Get data to cuda (that's our device, if it's possible)\n",
        "        data = data.to(device=device)\n",
        "\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # print (data.shape)\n",
        "\n",
        "        # Get to correct shape, which is a 2D matrix of 64 x 9, because model(x) of shape should be 64 x 2?\n",
        "        # Data is already in this correct shape, examine why?\n",
        "        # data = data.reshape(64, 9])\n",
        "\n",
        "        # by looking at this, we see we have 7 batches: 6 of size 64, 1 of size 38.\n",
        "\n",
        "        # forward propagation\n",
        "        scores = model(data)\n",
        "\n",
        "        # print(targets.shape)\n",
        "\n",
        "        targets = np.reshape(targets.to(device=torch.device('cpu')), [targets.shape[0], 1])\n",
        "        targets = targets.to(device=device)\n",
        "        \n",
        "        var = torch.ones(scores.shape[0], requires_grad = False)\n",
        "        var = np.reshape(var.to(device=torch.device('cpu')), [targets.shape[0], 1])\n",
        "        var = var.to(device=device)\n",
        "\n",
        "        # print (scores.shape, targets.shape, var.shape)\n",
        "\n",
        "        loss = criterion(scores, targets, var)\n",
        "\n",
        "        # backward propagation\n",
        "        optimizer.zero_grad() # set all gradients to 0 for each batch so it doesnt store calculation from previous batch\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_values.append(loss) # loss after each epoch\n",
        "\n",
        "plt.plot(np.array(loss_values), 'r')"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n",
            "torch.Size([256])\n",
            "torch.Size([256, 2]) torch.Size([256, 1]) torch.Size([256, 1])\n",
            "torch.Size([140])\n",
            "torch.Size([140, 2]) torch.Size([140, 1]) torch.Size([140, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff1549985d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBJOAYXNn38"
      },
      "source": [
        "## Check Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgWgMQdNpMe"
      },
      "source": [
        "def check_accuracy(loader, model):\n",
        "  \"\"\" if loader.dataset.train: # if this is true, then it is loading and checking training data\n",
        "    print ('Checking accuracy on training data')\n",
        "  else: \n",
        "    print ('Checking accuracy on testing data')\n",
        "\n",
        "  Appears to be error with this code  \n",
        "  \"\"\"\n",
        "\n",
        "  # initializing\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  y_pred = [] * 1\n",
        "  y_true = [] * 1\n",
        "\n",
        "  model.eval() # why this specifically?\n",
        "\n",
        "  with torch.no_grad(): # so we don't have to compute gradients for accuracy\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device)\n",
        "      y = y.to(device=device)\n",
        "\n",
        "      y_true.append(y)\n",
        "      \n",
        "      # reshape useless here\n",
        "      # x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "      scores = model(x)\n",
        "\n",
        "      # print (scores) # this returns 6 arrays of 64 x 2 and 1 of 38 x 2\n",
        "\n",
        "      # _, is don't store this part in anything\n",
        "      _, prediction = scores.max(1) # gives us index of maximum score value (max along second dimension, reason for the 1) in predictions variable each time\n",
        "      \n",
        "      y_pred.append(prediction)\n",
        "      \n",
        "      num_correct += (prediction == y).sum()\n",
        "      num_samples += prediction.size(0)\n",
        "\n",
        "  model.train()\n",
        "  acc = num_correct/num_samples\n",
        "  return acc, y_true, y_pred"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va66YK0T5Kin"
      },
      "source": [
        "# running check_accuracy on training and test set\n",
        "train_acc, y_train, train_pred = check_accuracy(train_loader, model)\n",
        "test_acc, y_test, test_pred = check_accuracy(test_loader, model)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsjzCJUyGHaU",
        "outputId": "a27666d0-618d-4198-d6f5-b5fd6506aa47"
      },
      "source": [
        "print(train_acc, test_acc)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.4318, device='cuda:0') tensor(0.5152, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ACg9G0g5UZ_",
        "outputId": "a9cab0c3-3c1e-49e8-f5fa-d4d18f4e7312"
      },
      "source": [
        "# The reason test_pred has two tensors is because it is 106 data, and 64 is batch size, so it happens in 1 batch of 64 and 1 batch of 42\n",
        "test_pred"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "         0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "         0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "         0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "         0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1je8nVNhAyhM"
      },
      "source": [
        "# consider if change batch size\n",
        "if (device == torch.device('cuda')):\n",
        "  test_pred = test_pred[0].to(device=cpu_device)\n",
        "  y_test = y_test[0].to(device=cpu_device)\n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhdqINChHEOW"
      },
      "source": [
        "# 256 batch size means no need to concatenate\n",
        "\n",
        "# test_pred = torch.cat(test_pred) # \n",
        "# y_test = torch.cat(y_test) # move tensor y_test to cpu for concatenation, gpu can't do that computationally"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFxWaU-x3msW"
      },
      "source": [
        "conf_mat = confusion_matrix(y_test, test_pred)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFfxcVS9I6ID"
      },
      "source": [
        "tn, fp, fn, tp = conf_mat.ravel()"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or_CoFhyI86d",
        "outputId": "f8548ac5-d9fe-47af-8150-48fa7a13fd4d"
      },
      "source": [
        "tp, fn, tn, fp"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 6, 41, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgF5DH6YJ4En"
      },
      "source": [
        "True positive + false negative = number of PD patients\n",
        "\n",
        "True negative + false positive = number of control patients"
      ]
    }
  ]
}