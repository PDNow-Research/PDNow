{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Numerical.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9PG2W/4WLADqIHyS7KP3D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PDNow-Research/PDNow/blob/main/HandPD/NeuralNets/NN_Numerical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGertFcjmEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37292bcd-7626-4480-87a3-9f2e0b4fd2a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9pOrBx_4cC"
      },
      "source": [
        "We are going to take text-based features and apply a simple, fully-connected neural network to them. Atually, let's use images - that's what the tutorial does. Let's only consider Meander for the time being."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eF1D-LjzNr"
      },
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Image Reading\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Other ML Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Torch General\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn # loss functions, neural network type (convolutional, linear, etc.)\n",
        "import torch.optim as optim # optimization functions (sgd)\n",
        "import torch.nn.functional as F # functions without parameters - activation functions (Relu, etc.) (also included in nn package, could use, but functional package is \"better\")\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets # torch has a LOT LOT LOT of standard datasets (ImageNet, MNIST, etc.)\n",
        "import torchvision.transforms as transforms # transformations for dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # PyTorch train test split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGjWjPnA2w3"
      },
      "source": [
        "Now to create the fully connected network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_16mfP3JkKp9"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, num_classes): # input-size = 611568 (size of our images, pixel number), num_classes = 2 (PD/no PD)\n",
        "    super(NN, self).__init__() # initializes the NN class that we're defining\n",
        "    self.fc1 = nn.Linear(input_size, 50) # 50 nodes\n",
        "    self.fc2 = nn.Linear(50, num_classes)\n",
        "\n",
        "  def forward(self, x): # run on some input x, which is the images which we run through fc1 and fc2 layers created above (and add the reLU activation function it between)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJ98iivMqS6"
      },
      "source": [
        "### Quick Test\n",
        "\n",
        "What the model should output it something of shape [264 (140 + 124), 2]. For each image, it should predict the probability of it being in class 1 or 2 and return both of those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHUZ9XHGEaVa",
        "outputId": "9934a1c9-05bc-48c7-db51-20207521becf"
      },
      "source": [
        "model = NN(611568, 2) \n",
        "\n",
        "# 124 patient images\n",
        "# 140 control images \n",
        "x = torch.randn(64, 611568) # 64 batch size\n",
        "\n",
        "print (model(x).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7oC7YSPkdtG"
      },
      "source": [
        "## Set Device + Init Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJcm8-PNalT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c7e1e3-2ac4-42b1-c4a6-8aaa7402d925"
      },
      "source": [
        "# Device set \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # google colab provides cuda gpu\n",
        "print (device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3nthTPetEQf"
      },
      "source": [
        "# Hyperparams\n",
        "input_size = 611568*3 \n",
        "# This 611568 comes from the size of each image (maxSize of an image). They have all been padded to be of this size. \n",
        "# We multiply by 3 because there are three color channels.\n",
        "num_classes = 2\n",
        "\n",
        "# tunables\n",
        "test_size = 0.2\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 2\n",
        "seed = 0 # just random state to start at"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FL-1eHknDM"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5gu2CV-kn8"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QSHyNkXuZAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75cad452-17ef-482c-c740-b2e8e2bcd0aa"
      },
      "source": [
        "# Load Data (possible to do it with Google Drive rather than uploading from computer?).\n",
        "# Uploaded can be nice tho... especially because it automatically goes to dictionary... that can be fed into NN, with file names as indexes - quite nice\n",
        "\n",
        "\"\"\" from google.colab import files\n",
        "uploaded = files.upload()\"\"\"\n",
        "\n",
        "# %cd \"/content/drive/\"My Drive\"/Data/Images/Meander/\"\n",
        "# X_train = np.load('HealthyMeander/HealthyMeander/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' from google.colab import files\\nuploaded = files.upload()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUoREyiB1uh8"
      },
      "source": [
        "# Healthy: Class 0 . PD: Class 1\n",
        "\n",
        "def extract_images(path, c): # path of data, class of data\n",
        "  filename_arr = []\n",
        "  X_arr = []\n",
        "\n",
        "  for file in glob.glob(path):\n",
        "    filename_arr.append(file) # filenames, not going to use them for now. Might need them later.\n",
        "    x = cv2.imread(file)\n",
        "    X_arr.append(x)\n",
        "\n",
        "  y_arr = [c] * len(X_arr)\n",
        "\n",
        "  return X_arr, y_arr\n",
        "\n",
        "# X_arr is a list of 3D arrays representing images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocDBvBlTGSuf"
      },
      "source": [
        "# possibly try different pad modes for better NN results? (instead of 'constant')\n",
        "def pad_images(arr):\n",
        "  arr = np.copy(arr)\n",
        "  largestX = 0\n",
        "  largestY = 0\n",
        "\n",
        "  def pad_condition(pad, largest, index):\n",
        "    if (2 * pad != (largest - arr[i].shape[index])):\n",
        "      pad1 = pad + 1\n",
        "      pad2 = pad\n",
        "    else:\n",
        "      pad1, pad2 = pad, pad\n",
        "    return pad1, pad2\n",
        "\n",
        "  for i in arr:\n",
        "    X = i.shape[0]\n",
        "    Y = i.shape[1]\n",
        "    if (X > largestX):\n",
        "      largestX = X\n",
        "    if (Y > largestY):\n",
        "      largestY = Y\n",
        "\n",
        "  for i in range(len(arr)):\n",
        "    X_pad = int((largestX - arr[i].shape[0]) /2) # pad equally in both directions, must be int\n",
        "    Y_pad = int((largestY - arr[i].shape[1]) /2)\n",
        "    \n",
        "    # but int floors, so we might get something of a slightly wrong shape (by 1), so...\n",
        "    X_pad1, X_pad2 = pad_condition(X_pad, largestX, 0)\n",
        "    Y_pad1, Y_pad2 = pad_condition(Y_pad, largestY, 1)\n",
        "\n",
        "    arr[i] = np.pad(arr[i], ((X_pad1, X_pad2), (Y_pad1, Y_pad2), (0, 0)), 'constant', constant_values=(0))\n",
        "\n",
        "  maxSize = largestX * largestY\n",
        "  \n",
        "  return arr, maxSize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgoIIjwgRJWk"
      },
      "source": [
        "def normalize_images(arr, num):\n",
        "  arr = arr/num\n",
        "  return arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "VaW62V2UM-en",
        "outputId": "0e29fd0d-7d81-42b0-a600-7cdbfb49cea6"
      },
      "source": [
        "\"\"\"X_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\n",
        "X_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\n",
        "\n",
        "X_all = X_meah + X_meap\n",
        "X_all, maxSize = pad_images(X_all)\n",
        "\n",
        "X_all = normalize_images(X_all, 255)\n",
        "\n",
        "y_all = np.array(y_meah + y_meap) \"\"\"\n",
        "\n",
        "# Why the warning particularly? "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\\nX_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\\n\\nX_all = X_meah + X_meap\\nX_all, maxSize = pad_images(X_all)\\n\\nX_all = normalize_images(X_all, 255)\\n\\ny_all = np.array(y_meah + y_meap) '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTuX0ihosiD"
      },
      "source": [
        "class MeanderDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # data loading\n",
        "    X_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\n",
        "    X_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\n",
        "\n",
        "    y_all = np.array(y_meah + y_meap)\n",
        "\n",
        "    X_all = X_meah + X_meap\n",
        "    X_all, maxSize = pad_images(X_all) # just padding all of the array's images to be the same size\n",
        "    X_all = normalize_images(X_all, 255) # normalizing from 0 to 255 - 0 to 1\n",
        "\n",
        "    X_all = np.stack(X_all, axis=0) # stacking into 4D tensor\n",
        "\n",
        "    self.n_samples = X_all.shape[0]\n",
        "\n",
        "    self.x = torch.from_numpy(X_all).float() # creates tensor from numpy array, making it float as expected by model\n",
        "    self.y = torch.from_numpy(y_all).long() # y_all is numpy array too, making it a long as expected by model\n",
        "  \n",
        "  # support indexing such that dataset[i] can be used to get i-th sample\n",
        "  def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "  # to return size\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5rlj-zaatPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b708fc4f-5303-4c3f-9cd9-22467ac7d47c"
      },
      "source": [
        "dataset = MeanderDataset() # Meander Dataset object\n",
        "\n",
        "# Why the warning?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:792: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, order=order, subok=subok, copy=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOCtKHuXv33-",
        "outputId": "2036ca70-b668-4d8a-fc48-25275a0c1b0c"
      },
      "source": [
        "first_row = dataset[0]\n",
        "feature0, label0 = first_row\n",
        "print(feature0, label0)\n",
        "\n",
        "# feature0 shape is 744, 822, 3\n",
        "# label0 is just 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]]) tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4NmhAIIwV-",
        "outputId": "38b68561-b076-469e-f8ac-a033e7355a15"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzYiS7yNNxBQ"
      },
      "source": [
        "### DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYxhzwoMiga"
      },
      "source": [
        "# Dataloader to load whole dataset\n",
        "# Shuffle: shuffle data, good for training\n",
        "# num_workers: faster loading with multiple subprocesses simultaneously, set to 0 if error occurs when loading"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vfo8yMzBh_b"
      },
      "source": [
        "# To perform train test split, we'll use sklearn... https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
        "\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, test_indices, _ , _ = train_test_split(\n",
        "    range(len(dataset)),\n",
        "    dataset.y,\n",
        "    stratify=dataset.y,\n",
        "    test_size=test_size,\n",
        "    random_state=seed\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk9e_kh9JPcR"
      },
      "source": [
        "# train_indices is indices of the training values while test_indices is indicies of the testing values. Let's split our data like such.\n",
        "\n",
        "# generate subset based on indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "test_dataset = Subset(dataset, test_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NNckzyJgiR",
        "outputId": "77b3b4ad-8acf-4cb1-b244-a3ee1985f04c"
      },
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(211, 53)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy29psB1Z8L"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers =2)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True, num_workers =2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTx3jhOBK8Ns"
      },
      "source": [
        "## Initialize Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-SEtZyLAUE"
      },
      "source": [
        "model = NN(input_size = input_size, num_classes = num_classes).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUS61pUBLFvk"
      },
      "source": [
        "# Loss + Optimizer\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate) # optimizer function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO7z25t4KIWY"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCNdQnCYKKxk",
        "outputId": "192e13f1-0ed5-4d14-812c-43255e2a4294"
      },
      "source": [
        "# epochs: number of times network sees images. 1 epoch - seen all images once\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader): # parts of the train_loader, (data,targets) in tuple together, batch_idx there before\n",
        "        \n",
        "        # Get data to cuda (that's our device, if it's possible)\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # Get to correct shape, which is one long, unrolled, vector of size 744 * 822 * 3 = 1834704\n",
        "        data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "        # by looking at this, we see we have 4 batches: 3 of size 64, 1 of size 19. Also, our shape is right now.\n",
        "        print (data.shape)\n",
        "\n",
        "        # forward (why called forward??) - forward propagation\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # backward (why called backward??) - backward propagation\n",
        "        optimizer.zero_grad() # set all gradients to 0 for each batch so it doesnt store calculation from previous batch\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1834704])\n",
            "torch.Size([64, 1834704])\n",
            "torch.Size([64, 1834704])\n",
            "torch.Size([19, 1834704])\n",
            "torch.Size([64, 1834704])\n",
            "torch.Size([64, 1834704])\n",
            "torch.Size([64, 1834704])\n",
            "torch.Size([19, 1834704])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBJOAYXNn38"
      },
      "source": [
        "## Check Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgWgMQdNpMe"
      },
      "source": [
        "def check_accuracy(loader, model):\n",
        "  \"\"\" if loader.dataset.train: # if this is true, then it is loading and checking training data\n",
        "    print ('Checking accuracy on training data')\n",
        "  else: \n",
        "    print ('Checking accuracy on testing data')\n",
        "\n",
        "  Appears to be error with this code  \n",
        "  \"\"\"\n",
        "\n",
        "  # initializing\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "\n",
        "  model.eval() # why this specifically?\n",
        "\n",
        "  with torch.no_grad(): # so we don't have to compute gradients for accuracy\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device)\n",
        "      y = y.to(device=device)\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "      scores = model(x)\n",
        "\n",
        "      # scores is size 264 * 2\n",
        "      # _, is don't store this part in anything\n",
        "      _, predictions = scores.max(1) # gives us index of maximum score value (max along second dimension, reason for the 1) in predictions variable each time\n",
        "      num_correct += (predictions == y).sum()\n",
        "      num_samples += predictions.size(0)\n",
        "\n",
        "  model.train()\n",
        "  acc = num_correct/num_samples\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzthtBRLOh4G",
        "outputId": "e14b707c-94a8-4317-a035-25b067949c1b"
      },
      "source": [
        "# running check_accuracy on training and test set\n",
        "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
        "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 46.92\n",
            "Accuracy on test set: 47.17\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}