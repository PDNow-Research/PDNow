{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNh1B57c/KL/Cl5hShnKoPY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PDNow-Research/PDNow/blob/main/HandPD/NeuralNets/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGertFcjmEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac979aff-29e9-4ab2-b922-015168d87699"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9pOrBx_4cC"
      },
      "source": [
        "We are going to take text-based features and apply a simple, fully-connected neural network to them. Atually, let's use images - that's what the tutorial does. Let's only consider Meander for the time being."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eF1D-LjzNr"
      },
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Image Reading\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Other ML Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Torch General\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn # loss functions, neural network type (convolutional, linear, etc.)\n",
        "import torch.optim as optim # optimization functions (sgd)\n",
        "import torch.nn.functional as F # functions without parameters - activation functions (Relu, etc.) (also included in nn package, could use, but functional package is \"better\")\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets # torch has a LOT LOT LOT of standard datasets (ImageNet, MNIST, etc.)\n",
        "import torchvision.transforms as transforms # transformations for dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # PyTorch train test split"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGjWjPnA2w3"
      },
      "source": [
        "Now to create the fully connected network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_16mfP3JkKp9"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, num_classes): # input-size = 611568 (size of our images, pixel number), num_classes = 2 (PD/no PD)\n",
        "    super(NN, self).__init__() # initializes the NN class that we're defining\n",
        "    self.fc1 = nn.Linear(input_size, 50) # 50 nodes\n",
        "    self.fc2 = nn.Linear(50, num_classes)\n",
        "\n",
        "  def forward(self, x): # run on some input x, which is the images which we run through fc1 and fc2 layers created above (and add the reLU activation function it between)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJ98iivMqS6"
      },
      "source": [
        "### Quick Test\n",
        "\n",
        "What the model should output it something of shape [264 (140 + 124), 2]. For each image, it should predict the probability of it being in class 1 or 2 and return both of those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHUZ9XHGEaVa",
        "outputId": "d62d3b15-0786-4f89-fed6-30178c4a400a"
      },
      "source": [
        "model = NN(611568, 2) \n",
        "\n",
        "# 124 patient images\n",
        "# 140 control images \n",
        "x = torch.randn(264, 611568) \n",
        "\n",
        "print (model(x).shape)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([264, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7oC7YSPkdtG"
      },
      "source": [
        "## Set Device + Init Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJcm8-PNalT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdab6004-43af-4307-f49c-5f048f4e15e8"
      },
      "source": [
        "# Device set \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # google colab provides cuda gpu\n",
        "print (device)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3nthTPetEQf"
      },
      "source": [
        "# Hyperparams\n",
        "input_size = 611568 # this 611568 comes from the size of each image (maxSize of an image). They have all been padded to be of this size.\n",
        "num_classes = 2\n",
        "\n",
        "# tunables\n",
        "test_size = 0.2\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 1\n",
        "seed = 0 # just random state to start at"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FL-1eHknDM"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5gu2CV-kn8"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QSHyNkXuZAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "51d6280e-7436-4079-8955-55cea106568b"
      },
      "source": [
        "# Load Data (possible to do it with Google Drive rather than uploading from computer?).\n",
        "# Uploaded can be nice tho... especially because it automatically goes to dictionary... that can be fed into NN, with file names as indexes - quite nice\n",
        "\n",
        "\"\"\" from google.colab import files\n",
        "uploaded = files.upload()\"\"\"\n",
        "\n",
        "# %cd \"/content/drive/\"My Drive\"/Data/Images/Meander/\"\n",
        "# X_train = np.load('HealthyMeander/HealthyMeander/')\n"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' from google.colab import files\\nuploaded = files.upload()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUoREyiB1uh8"
      },
      "source": [
        "# Healthy: Class 0 . PD: Class 1\n",
        "\n",
        "def extract_images(path, c): # path of data, class of data\n",
        "  filename_arr = []\n",
        "  X_arr = []\n",
        "\n",
        "  for file in glob.glob(path):\n",
        "    filename_arr.append(file) # filenames, not going to use them for now. Might need them later.\n",
        "    x = cv2.imread(file)\n",
        "    X_arr.append(x)\n",
        "  \n",
        "  y_arr = [c] * len(X_arr)\n",
        "\n",
        "  return X_arr, y_arr\n",
        "\n",
        "# X_arr is a list of 3D arrays representing images"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocDBvBlTGSuf"
      },
      "source": [
        "# possibly try different pad modes for better NN results? (instead of 'constant')\n",
        "def pad_images(arr):\n",
        "  arr = np.copy(arr)\n",
        "  largestX = 0\n",
        "  largestY = 0\n",
        "\n",
        "  def pad_condition(pad, largest, index):\n",
        "    if (2 * pad != (largest - arr[i].shape[index])):\n",
        "      pad1 = pad + 1\n",
        "      pad2 = pad\n",
        "    else:\n",
        "      pad1, pad2 = pad, pad\n",
        "    return pad1, pad2\n",
        "\n",
        "  for i in arr:\n",
        "    X = i.shape[0]\n",
        "    Y = i.shape[1]\n",
        "    if (X > largestX):\n",
        "      largestX = X\n",
        "    if (Y > largestY):\n",
        "      largestY = Y\n",
        "\n",
        "  for i in range(len(arr)):\n",
        "    X_pad = int((largestX - arr[i].shape[0]) /2) # pad equally in both directions, must be int\n",
        "    Y_pad = int((largestY - arr[i].shape[1]) /2)\n",
        "    \n",
        "    # but int floors, so we might get something of a slightly wrong shape (by 1), so...\n",
        "    X_pad1, X_pad2 = pad_condition(X_pad, largestX, 0)\n",
        "    Y_pad1, Y_pad2 = pad_condition(Y_pad, largestY, 1)\n",
        "\n",
        "    arr[i] = np.pad(arr[i], ((X_pad1, X_pad2), (Y_pad1, Y_pad2), (0, 0)), 'constant', constant_values=(0))\n",
        "\n",
        "  maxSize = largestX * largestY\n",
        "  \n",
        "  return arr, maxSize"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "VaW62V2UM-en",
        "outputId": "69fd420f-919a-4ec4-d068-fea4aeac4186"
      },
      "source": [
        "\"\"\"\n",
        "X_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\n",
        "X_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\n",
        "\n",
        "X_all = X_meah + X_meap\n",
        "X_all, maxSize = pad_images(X_all)\n",
        "\n",
        "y_all = y_meah + y_meap\"\"\""
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nX_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\\nX_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\\n\\nX_all = X_meah + X_meap\\nX_all, maxSize = pad_images(X_all)\\n\\ny_all = y_meah + y_meap'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTuX0ihosiD"
      },
      "source": [
        "class MeanderDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # data loading\n",
        "    X_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\n",
        "    X_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\n",
        "\n",
        "    y_all = y_meah + y_meap\n",
        "    X_all = X_meah + X_meap\n",
        "    X_all, maxSize = pad_images(X_all) # just padding all of the array's images to be the same size\n",
        "\n",
        "    X_all = np.stack(X_all, axis=0) # stacking into 4D tensor\n",
        "\n",
        "    self.n_samples = X_all.shape[0]\n",
        "\n",
        "    self.x = torch.from_numpy(X_all) # creates tensor from numpy array\n",
        "    self.y = torch.Tensor(y_all) # y_all is a list, not a numpy array\n",
        "  \n",
        "  # support indexing such that dataset[i] can be used to get i-th sample\n",
        "  def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "  # to return size\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5rlj-zaatPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f7c560-b0ed-43e7-b7cd-b8239ff426d3"
      },
      "source": [
        "dataset = MeanderDataset() # Meander Dataset object"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:792: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, order=order, subok=subok, copy=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOCtKHuXv33-"
      },
      "source": [
        "first_row = dataset[0]\n",
        "feature0, label0 = first_row\n",
        "print(feature0, label0)\n",
        "\n",
        "# feature0 shape is 744, 822, 3\n",
        "# label0 is just 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4NmhAIIwV-",
        "outputId": "5fbe53fb-5827-4aa1-a3a1-c4204132626c"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzYiS7yNNxBQ"
      },
      "source": [
        "### DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYxhzwoMiga"
      },
      "source": [
        "# Dataloader to load whole dataset\n",
        "# Shuffle: shuffle data, good for training\n",
        "# num_workers: faster loading with multiple subprocesses simultaneously, set to 0 if error occurs when loading"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vfo8yMzBh_b"
      },
      "source": [
        "# To perform train test split, we'll use sklearn... https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
        "\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, test_indices, _ , _ = train_test_split(\n",
        "    range(len(dataset)),\n",
        "    dataset.y,\n",
        "    stratify=dataset.y,\n",
        "    test_size=test_size,\n",
        "    random_state=seed\n",
        ")"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk9e_kh9JPcR"
      },
      "source": [
        "# train_indices is indices of the training values while test_indices is indicies of the testing values. Let's split our data like such.\n",
        "\n",
        "# generate subset based on indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "test_dataset = Subset(dataset, test_indices)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NNckzyJgiR",
        "outputId": "c4a7eb87-5eeb-4978-944c-8156dbf41029"
      },
      "source": [
        "len(train_split), len(test_split)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(211, 53)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy29psB1Z8L"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_split, batch_size = batch_size, shuffle = True, num_workers =2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Mi5tut-g2D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}